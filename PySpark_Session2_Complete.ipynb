{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e71ab2-d8ea-477f-b8de-a39c7bf4dd1c",
   "metadata": {},
   "source": [
    "So far we've used toy examples to introduce the RDD API along with a few of its Transformations and Actions. Now let's look at a more real-life example: let's wrangle a fairly big \"semi-structured\" file and turn it into something a Data Scientist would be ready to work with. In fact, let's ask a few Data Science-y questions of this data and use Spark itself to answer them while we are at it!\n",
    "\n",
    "In order to continue with this lesson, first download the required data files and put it in your data folder inside your working directory.\n",
    "\n",
    "This example file is a standard Apache web server log. It's the logs from a month's worth of requests to NASA's website, in the distant year of 1995, combined into one fairly big file to be more specific.\n",
    "\n",
    "This log contains the following information:\n",
    "\n",
    "* The IP Address or the DNS name performing a request\n",
    "* A time stamp of the form: \"dd/Mon/YYYY:hh:mm:ss Timezone\"\n",
    "* The request type (HTTP verb), the resource being requested and the Protocol used\n",
    "* The code returned by the server (200 OK, 400 Not Found etc...)\n",
    "* The Size of the resource being requested\n",
    "\n",
    "We will use the textFile method to read in this file. This, like the parallelize method, turns the data inside this file into an RDD. There are two important things you need to know about this method: \n",
    "\n",
    "* In a real-life Spark Cluster, the location of the file (the argument you will pass to textFile) must be visible/accessible to all nodes of the Cluster. In practice, a lot of the time this location will be a path on a Hadoop Distributed File System (HDFS), but this can be any Network File System, or a location mounted on all nodes, or Amazon S3... as long as it's visible and accessible on all nodes! \n",
    "\n",
    "* This method turns each line of the input file into an element in a Partition. So ,no matter what the format of the file is, when it gets turned into an RDD, each line (as delimited by a newline a.k.a. \"\\n\") becomes an element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6658ed1-af8d-4d81-8fb0-f9826e7e3e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's import pyspark, initialize a Spark connection\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "#Let's read NASA logs as a textfile into a variable and find out the type of variable we defined here\n",
    "nasa_logs = sc.textFile('data/NASA_access_log_Jul95.gz')\n",
    "type(nasa_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcfe16b-3641-45ba-92a2-c4b4c53217e4",
   "metadata": {},
   "source": [
    "The first step in any data problem is to look at the data to get a sense of what we are dealing with. A good practice is to find out how many elements we have to get a sense of what we are dealing with. The RDD API has the count method for that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a14c44f2-d7ba-4984-805d-3a6ab452aac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1891715"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use count() method to see how many elements (lines) are in the NASA logs\n",
    "nasa_logs.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f79a7-a68f-4252-ac4e-872e4df55410",
   "metadata": {},
   "source": [
    "The RDD API has the take Action, that brings a number of elements (remember, an element here is a line of the original file) back to the Driver so we can see them. The important thing here is to be careful not to bring too many elements back to Driver and blow up its memory capacity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8333b5e-e6f4-4cf2-a307-a9dc6fd2a1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use take() action to bring a number of elements from Cluster back to the Driver!\n",
    "nasa_logs.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05ca7ba-3c1a-4128-8160-aac8dd22bb7f",
   "metadata": {},
   "source": [
    "Now that we can see what the data looks like, a reasonable first step seems to be to split the data on the \" \" (space) character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be64964-6234-4768-a29d-aedfb2bb3031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['199.72.81.55',\n",
       "  '-',\n",
       "  '-',\n",
       "  '[01/Jul/1995:00:00:01',\n",
       "  '-0400]',\n",
       "  '\"GET',\n",
       "  '/history/apollo/',\n",
       "  'HTTP/1.0\"',\n",
       "  '200',\n",
       "  '6245']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data on space characters\n",
    "nasa_logs.map(lambda line : line.split(\" \")).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bfc5f5-0d20-4283-b413-e3cf7bce1d42",
   "metadata": {},
   "source": [
    "Next, for the sake of this example, let's say we are not interested in lines where there is data missing. In other words, we are only interested in lines that have all 10 elements. We will use the filter method to filter any lines that don't have all 10 elements out of our RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b148a1f-fb8d-42a7-8693-1575d4f77da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1886891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data and count the lines that have 10 exactly elements\n",
    "\n",
    "nasa_logs.map(lambda line : line.split(\" \")).\\\n",
    "filter(lambda line : len(line)==10).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8b0c8-8490-47b5-9f63-66fcc463a921",
   "metadata": {},
   "source": [
    "\n",
    "This line of code in PySpark performs a series of operations to count the number of lines in the \n",
    "nasa_logs RDD that have exactly 10 words (or elements) separated by spaces.\n",
    "\n",
    "You might be asking yourself whether using the take method all the time to check if we are doing things right is the best practice... and the answer is no. Everytime you call it, you are computing a new RDD and thus having the Spark Cluster do work for you. In real-life you will rarely have a Cluster all for yourself, so you should expect your computations to get queued and competing for resources with other users. in this scenario, minimizing the amount of times you move things back and forth between the Driver and the Executors is a good idea.\n",
    "\n",
    "So in practice, one approach would be to use the RDD API method sample to extract a sample of your data to examine in the driver and figure out what you need to do before farming out computations to the cluster. The take method also works here, but getting a random sample (using sample() method) instead of the first N elements of your RDD is almost always a better plan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcaf0371-dc63-41d6-a7b1-970f47ca030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eic69.fiu.edu - - [01/Jul/1995:09:40:25 -0400] \"GET /shuttle/missions/sts-71/images/KSC-95EC-0544.jpg HTTP/1.0\" 200 70128', 'ix-li1-26.ix.netcom.com - - [01/Jul/1995:14:03:09 -0400] \"GET /shuttle/missions/51-l/docs/ HTTP/1.0\" 200 368', 'ppp-hck-1-7.ios.com - - [01/Jul/1995:16:16:17 -0400] \"GET /shuttle/missions/sts-71/movies/sts-71-launch-2.mpg HTTP/1.0\" 200 543680', '204.117.201.58 - - [01/Jul/1995:16:53:14 -0400] \"GET /images/whatsnew.gif HTTP/1.0\" 200 651', 'barne002.mc.duke.edu - - [01/Jul/1995:18:34:36 -0400] \"GET /shuttle/missions/sts-71/images/KSC-95EC-0891.txt HTTP/1.0\" 200 799', 'ix-pa1-05.ix.netcom.com - - [01/Jul/1995:19:04:16 -0400] \"GET /shuttle/missions/sts-71/images/KSC-95EC-0913.jpg HTTP/1.0\" 200 25439', 'denjo.seanet.com - - [02/Jul/1995:00:33:39 -0400] \"GET /cgi-bin/imagemap/countdown?93,171 HTTP/1.0\" 302 110', 'garymak.pr.mcs.net - - [02/Jul/1995:06:15:32 -0400] \"GET /shuttle/missions/sts-71/sts-71-patch-small.gif HTTP/1.0\" 200 12054', 'ad02-011.compuserve.com - - [02/Jul/1995:13:41:23 -0400] \"GET /elv/TITAN/titan.gif HTTP/1.0\" 200 3530', 'ix-sr3-01.ix.netcom.com - - [02/Jul/1995:16:49:29 -0400] \"GET /facilities/mlp.html HTTP/1.0\" 200 2653', '205.139.200.21 - - [02/Jul/1995:17:22:27 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 304 0', 'ip043220.iac.net - - [02/Jul/1995:20:27:29 -0400] \"GET /shuttle/missions/51-l/mission-51-l.html HTTP/1.0\" 200 6723', '199.86.26.149 - - [02/Jul/1995:20:31:30 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'emerald.angustel.nstn.ca - - [02/Jul/1995:21:24:27 -0400] \"GET /shuttle/missions/sts-71/images/KSC-95EC-0911.gif HTTP/1.0\" 200 31242', 'piweba1y.prodigy.com - - [03/Jul/1995:00:24:17 -0400] \"GET /shuttle/missions/sts-71/images/KSC-95EC-0902.gif HTTP/1.0\" 200 29763', 'ppp-3-30.iadfw.net - - [03/Jul/1995:00:42:06 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'ip135.phx.primenet.com - - [03/Jul/1995:11:45:39 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 200 5866', 'wswiop03.win.tue.nl - - [03/Jul/1995:12:13:50 -0400] \"GET /shuttle/missions/sts-71/sts-71-patch-small.gif HTTP/1.0\" 200 12054', 'ip239.fresno.ca.interramp.com - - [03/Jul/1995:17:52:08 -0400] \"GET /persons/nasa-cm/jmd.html HTTP/1.0\" 200 3933', '204.248.155.27 - - [03/Jul/1995:22:18:32 -0400] \"GET /shuttle/resources/orbiters/atlantis-logo.gif HTTP/1.0\" 200 4179', 'vcgate0.mei.co.jp - - [03/Jul/1995:23:39:28 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713', 'ns.prismsys.bc.ca - - [03/Jul/1995:23:58:03 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713', 'hplb.hpl.hp.com - - [04/Jul/1995:06:23:10 -0400] \"GET /shuttle/missions/sts-71/sts-71-patch-small.gif HTTP/1.0\" 200 12054', 'srq005.packet.net - - [04/Jul/1995:12:57:11 -0400] \"GET /images/shuttle-patch-small.gif HTTP/1.0\" 200 4179', 'ssdd475a.erim.org - - [04/Jul/1995:15:48:12 -0400] \"GET /icons/image.xbm HTTP/1.0\" 200 509', 'ad13-032.compuserve.com - - [05/Jul/1995:02:48:18 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'dutsp87.tudelft.nl - - [05/Jul/1995:02:48:54 -0400] \"GET /shuttle/missions/sts-63/sts-63-patch.jpg HTTP/1.0\" 200 57344', '130.226.96.119 - - [05/Jul/1995:06:08:00 -0400] \"GET /icons/text.xbm HTTP/1.0\" 200 527', 'skippy.uniplex.co.uk - - [05/Jul/1995:06:14:15 -0400] \"GET /shuttle/missions/sts-71/images/KSC-95EC-0913.jpg HTTP/1.0\" 200 25439', 'pl03809.ksc.nasa.gov - - [05/Jul/1995:06:54:52 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', '128.159.124.68 - - [05/Jul/1995:10:42:53 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', 'dxl-pc.sprmc.healthpartners.com - - [05/Jul/1995:11:12:16 -0400] \"GET /history/apollo/apollo-13/apollo-13.html HTTP/1.0\" 200 18114', '204.242.174.244 - - [05/Jul/1995:11:24:52 -0400] \"GET /shuttle/missions/sts-45/sts-45-patch-small.gif HTTP/1.0\" 200 14647', 'pacific28217.cc.odu.edu - - [05/Jul/1995:12:24:40 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', 'ix-esc-ca1-15.ix.netcom.com - - [05/Jul/1995:15:34:29 -0400] \"GET /shuttle/technology/sts-newsref/sts_asm.html HTTP/1.0\" 200 71656', 'triton.sbu.edu - - [05/Jul/1995:23:55:22 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', 'ip-vanc1-11.teleport.com - - [06/Jul/1995:00:06:11 -0400] \"GET /images/kscmap-tiny.gif HTTP/1.0\" 200 2537', 'ntcfd01.ntc.nokia.com - - [06/Jul/1995:00:30:02 -0400] \"GET /cgi-bin/imagemap/countdown?110,173 HTTP/1.0\" 302 110', 'slip137-8.pt.uk.ibm.net - - [06/Jul/1995:05:35:20 -0400] \"GET / HTTP/1.0\" 200 7067', 'slsyd2p45.ozemail.com.au - - [06/Jul/1995:07:15:29 -0400] \"GET /shuttle/missions/sts-71/sts-71-patch-small.gif HTTP/1.0\" 200 12054', 'poppy.hensa.ac.uk - - [06/Jul/1995:11:30:05 -0400] \"GET /shuttle/missions/sts-74/ HTTP/1.0\" 200 1596', 'hgrunin.navsea.navy.mil - - [06/Jul/1995:14:00:33 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'slip16.niagara.com - - [06/Jul/1995:22:03:30 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 200 4524', '205.236.175.122 - - [07/Jul/1995:00:48:00 -0400] \"GET /shuttle/countdown/count.gif HTTP/1.0\" 200 40310', 'bruce-mac.umd.edu - - [07/Jul/1995:07:21:55 -0400] \"GET /facilities/spaceport-logo-small.gif HTTP/1.0\" 304 0', 'fog.aer.com - - [07/Jul/1995:08:27:18 -0400] \"GET /images/ksclogosmall.gif HTTP/1.0\" 200 3635', 'poppy.hensa.ac.uk - - [07/Jul/1995:10:00:07 -0400] \"GET /shuttle/missions/sts-71/movies/movies.html HTTP/1.0\" 200 3089', 'gatekeeper.ray.com - - [07/Jul/1995:12:02:55 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 200 4871', '163.206.89.4 - - [07/Jul/1995:12:30:58 -0400] \"GET /icons/blank.xbm HTTP/1.0\" 200 509', 'melita.melita.com - - [07/Jul/1995:15:29:50 -0400] \"GET /icons/text.xbm HTTP/1.0\" 200 527', 'dd07-003.compuserve.com - - [07/Jul/1995:20:17:07 -0400] \"GET / HTTP/1.0\" 200 7067', '38.11.104.235 - - [07/Jul/1995:23:59:46 -0400] \"GET /shuttle/missions/sts-71/images/images.html HTTP/1.0\" 200 7634', 'minyos.xx.rmit.edu.au - - [10/Jul/1995:04:12:01 -0400] \"GET /shuttle/missions/51-l/51-l-patch-small.gif HTTP/1.0\" 200 10495', 'cioccac.pgh.wec.com - - [10/Jul/1995:07:46:16 -0400] \"GET /icons/blank.xbm HTTP/1.0\" 200 509', 'gcsin1.gecm.com - - [10/Jul/1995:12:06:55 -0400] \"GET /images/whatsnew.gif HTTP/1.0\" 200 651', 'ix-cin3-19.ix.netcom.com - - [11/Jul/1995:10:16:25 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 200 363', 'seaquest.cc.odu.edu - - [11/Jul/1995:12:17:41 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 4247', 'l23jp.jsc.nasa.gov - - [11/Jul/1995:12:59:38 -0400] \"GET /shuttle/missions/sts-49/sts-49-patch-small.gif HTTP/1.0\" 200 11628', 'bill.ksc.nasa.gov - - [11/Jul/1995:15:21:13 -0400] \"GET /shuttle/countdown/images/cdtclock.gif HTTP/1.0\" 304 0', 'stlgate.almaden.ibm.com - - [11/Jul/1995:16:12:25 -0400] \"GET /images/kscmap-tiny.gif HTTP/1.0\" 200 2537', 'wfr-20-1.rz.uni-frankfurt.de - - [11/Jul/1995:18:43:06 -0400] \"GET /images/ksclogosmall.gif HTTP/1.0\" 200 3635', 'ad01-002.compuserve.com - - [11/Jul/1995:20:04:54 -0400] \"GET /ksc.html HTTP/1.0\" 200 7062', 'ix-stp-fl2-03.ix.netcom.com - - [11/Jul/1995:21:43:02 -0400] \"GET /shuttle/missions/sts-70/sts-70-patch-small.gif HTTP/1.0\" 200 5026', 'pbadri-ss10.cisco.com - - [12/Jul/1995:04:41:51 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'gate1.btco.com - - [12/Jul/1995:05:50:51 -0400] \"GET /shuttle/missions/sts-70/images/images.html HTTP/1.0\" 200 4048', 'maccabee.lin.foa.se - - [12/Jul/1995:06:03:48 -0400] \"GET /shuttle/technology/sts-newsref/sts_asm.html HTTP/1.0\" 200 57344', 'pm2_5.digital.net - - [12/Jul/1995:08:17:32 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', '139.169.229.61 - - [12/Jul/1995:08:32:15 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 4247', 'hydro.mse.ufl.edu - - [12/Jul/1995:09:37:18 -0400] \"GET /htbin/cdt_clock.pl HTTP/1.0\" 200 751', '199.34.46.120 - - [12/Jul/1995:09:48:58 -0400] \"GET /history/apollo/apollo.html HTTP/1.0\" 200 3260', 'n1123211.ksc.nasa.gov - - [12/Jul/1995:10:02:37 -0400] \"GET /shuttle/countdown/images/cdtclock.gif HTTP/1.0\" 200 34688', '198.133.29.18 - - [12/Jul/1995:10:13:14 -0400] \"GET /images/ksclogosmall.gif HTTP/1.0\" 200 3635', 'rsimmons.arc.nasa.gov - - [12/Jul/1995:12:06:08 -0400] \"GET /cgi-bin/imagemap/countdown70?63,152 HTTP/1.0\" 302 111', 'e659229.boeing.com - - [12/Jul/1995:18:45:43 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 200 363', 'utsmc-2.swmed.edu - - [13/Jul/1995:02:04:03 -0400] \"GET /shuttle/countdown/lps/ab/ab.html HTTP/1.0\" 200 3933', 'n1122791.ksc.nasa.gov - - [13/Jul/1995:08:02:57 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 4247', 'twip.prl.philips.nl - - [13/Jul/1995:08:59:21 -0400] \"GET /htbin/cdt_main.pl HTTP/1.0\" 200 3585', 'msn_2_4.binc.net - - [13/Jul/1995:09:48:13 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0', 'proxy0.research.att.com - - [13/Jul/1995:11:00:09 -0400] \"GET /shuttle/missions/sts-41/sts-41-patch.jpg HTTP/1.0\" 200 304560', '199.117.60.32 - - [13/Jul/1995:11:05:39 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 200 363', 'b7w1.isd.ornl.gov - - [13/Jul/1995:11:40:27 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 49551', 'maple.cc.vt.edu - - [13/Jul/1995:12:56:49 -0400] \"GET /shuttle/missions/sts-70/sts-70-patch-small.gif HTTP/1.0\" 200 5026', '128.159.135.27 - - [13/Jul/1995:14:47:08 -0400] \"GET /shuttle/missions/sts-71/sts-71-patch-small.gif HTTP/1.0\" 200 12054', 'farlink.ll.mit.edu - - [13/Jul/1995:15:14:03 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 200 3564', 'mthwpc7.cc.purdue.edu - - [13/Jul/1995:15:40:43 -0400] \"GET /shuttle/countdown/count70.gif HTTP/1.0\" 200 46573', 'powjack.powell.com - - [13/Jul/1995:16:43:04 -0400] \"GET /shuttle/missions/sts-71/images/KSC-95EC-0911.gif HTTP/1.0\" 200 31242', 'emerald.cybergate.com - - [14/Jul/1995:01:49:28 -0400] \"GET /software/winvn/userguide/wvnguide.gif HTTP/1.0\" 200 4151', 'pm2_22.digital.net - - [14/Jul/1995:04:00:29 -0400] \"GET /cgi-bin/imagemap/countdown70?395,286 HTTP/1.0\" 302 68', 'vagrant.vf.mmc.com - - [14/Jul/1995:08:48:57 -0400] \"GET /history/history.html HTTP/1.0\" 200 1602', '163.205.23.71 - - [14/Jul/1995:08:52:42 -0400] \"GET / HTTP/1.0\" 200 7071', 'mahpc12.chem-eng.nwu.edu - - [14/Jul/1995:11:46:19 -0400] \"GET /shuttle/technology/images/srb_16-small.gif HTTP/1.0\" 200 42732', 'blv-pm1-ip27.halcyon.com - - [15/Jul/1995:00:10:56 -0400] \"GET /ksc.html HTTP/1.0\" 200 7071', 'lphipps.rust.net - - [15/Jul/1995:20:02:09 -0400] \"GET /shuttle/technology/images/mission_profile_2-small.gif HTTP/1.0\" 200 35540', 'www-d4.proxy.aol.com - - [15/Jul/1995:23:47:12 -0400] \"GET / HTTP/1.0\" 200 7071', 'dp059.ppp.iglou.com - - [16/Jul/1995:02:15:30 -0400] \"GET /shuttle/missions/sts-70/movies/sts-70-launch-srbsep.mpg HTTP/1.0\" 200 190757', '199.67.53.207 - - [16/Jul/1995:13:14:59 -0400] \"GET /elv/DELTA/delta.gif HTTP/1.0\" 200 2244', 'siltb10.orl.mmc.com - - [16/Jul/1995:22:05:14 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713', 'garnet.uchicago.edu - - [16/Jul/1995:23:11:06 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', 'ix-bal2-24.ix.netcom.com - - [16/Jul/1995:23:46:07 -0400] \"GET /shuttle/countdown/count70.gif HTTP/1.0\" 200 46573', '136.205.215.176 - - [17/Jul/1995:10:03:33 -0400] \"GET /history/apollo/apollo-8/apollo-8.html HTTP/1.0\" 200 3549', '163.205.125.12 - - [17/Jul/1995:11:05:26 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 200 234', 'gater3.sematech.org - - [17/Jul/1995:12:01:13 -0400] \"GET /shuttle/missions/sts-70/mission-sts-70.html HTTP/1.0\" 200 14745', 'ts02-ind-20.iquest.net - - [17/Jul/1995:14:24:20 -0400] \"GET /icons/blank.xbm HTTP/1.0\" 200 509', 'rwja.umdnj.edu - - [17/Jul/1995:14:37:24 -0400] \"GET /images/launchmedium.gif HTTP/1.0\" 200 11853', 'dd01-037.compuserve.com - - [17/Jul/1995:16:16:44 -0400] \"GET /history/apollo/images/footprint-small.gif HTTP/1.0\" 200 18149', 'e9.iea.com - - [17/Jul/1995:19:08:19 -0400] \"GET /shuttle/countdown/video/livevideo2.gif HTTP/1.0\" 200 65576', '192.190.49.128 - - [17/Jul/1995:20:53:42 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 304 0', 'ix-okc-ok1-22.ix.netcom.com - - [17/Jul/1995:23:42:12 -0400] \"GET /history/apollo/apollo-11/sounds/A01106AA.WAV HTTP/1.0\" 200 96036', 'edams.ksc.nasa.gov - - [18/Jul/1995:05:13:41 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', '134.136.243.100 - - [18/Jul/1995:08:45:37 -0400] \"GET /cgi-bin/imagemap/countdown70?350,278 HTTP/1.0\" 302 98', 'ix-aus2-08.ix.netcom.com - - [18/Jul/1995:09:04:06 -0400] \"GET /ksc.html HTTP/1.0\" 200 7071', '128.158.54.27 - - [18/Jul/1995:10:25:10 -0400] \"GET /shuttle/missions/missions.html HTTP/1.0\" 200 8678', '128.159.123.29 - - [18/Jul/1995:11:50:05 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 4267', '128.104.235.126 - - [18/Jul/1995:15:00:44 -0400] \"GET /shuttle/missions/sts-70/images/KSC-95EC-0649.gif HTTP/1.0\" 200 30043', '163.205.23.133 - - [18/Jul/1995:15:51:09 -0400] \"GET /shuttle/missions/51-l/51-l-info.html HTTP/1.0\" 200 1387', 'glass.toledolink.com - - [18/Jul/1995:20:33:58 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 200 234', 'gw1.att.com - - [19/Jul/1995:10:29:27 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 304 0', 'sagami2.isc.meiji.ac.jp - - [19/Jul/1995:10:58:05 -0400] \"GET / HTTP/1.0\" 200 7071', 'www-c5.proxy.aol.com - - [19/Jul/1995:13:00:03 -0400] \"GET /shuttle/missions/missions.html HTTP/1.0\" 304 0', 'benspc.oss.interact.net - - [19/Jul/1995:15:46:10 -0400] \"GET /images/launchmedium.gif HTTP/1.0\" 200 11853', 'dal04-22.ppp.iadfw.net - - [19/Jul/1995:22:58:12 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 200 5866', 'jvc-k4.krhm.jvc-victor.co.jp - - [20/Jul/1995:06:52:19 -0400] \"GET /shuttle/missions/51-l/images/ HTTP/1.0\" 200 1038', 'grumpy.ksc.nasa.gov - - [20/Jul/1995:09:03:23 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 200 234', 'huey.usask.ca - - [20/Jul/1995:16:40:37 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 200 669', '205.206.145.254 - - [20/Jul/1995:17:18:21 -0400] \"GET /images/mlp.gif HTTP/1.0\" 200 278528', '202.239.48.3 - - [20/Jul/1995:23:58:48 -0400] \"GET /images/launchmedium.gif HTTP/1.0\" 200 11853', 'gate.kajima.co.jp - - [21/Jul/1995:06:15:09 -0400] \"GET /history/apollo/images/apollo-logo1.gif HTTP/1.0\" 200 1173', '163.205.166.15 - - [21/Jul/1995:14:48:31 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0', 'dialup31-hugin.oden.se - - [21/Jul/1995:15:37:38 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 200 363', '163.205.106.18 - - [21/Jul/1995:16:13:52 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'slip-30.ieway.com - - [21/Jul/1995:17:30:14 -0400] \"GET /software/winvn/winvn.html HTTP/1.0\" 200 9867', 'www-d1.proxy.aol.com - - [21/Jul/1995:20:52:54 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', 'ix-pa11-16.ix.netcom.com - - [22/Jul/1995:01:12:53 -0400] \"GET /icon/new01.gif HTTP/1.0\" 200 1016', 'ip075.lax.primenet.com - - [22/Jul/1995:04:05:10 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'ad09-062.compuserve.com - - [22/Jul/1995:17:29:09 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 200 669', 'yvr-ppp-34.cyberstore.ca - - [23/Jul/1995:03:10:22 -0400] \"GET /images/ksclogosmall.gif HTTP/1.0\" 200 3635', 'host62.ascend.interop.eunet.de - - [23/Jul/1995:12:25:54 -0400] \"GET /images/launchpalms-small.gif HTTP/1.0\" 304 0', 'hnwb704.resnet.upenn.edu - - [23/Jul/1995:13:37:23 -0400] \"GET /history/apollo/images/apollo-logo.gif HTTP/1.0\" 200 3047', 'prihodko.paco.odessa.ua - - [23/Jul/1995:18:38:14 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 4324', 'mickey.tc.cornell.edu - - [23/Jul/1995:19:26:24 -0400] \"GET /images/ksclogosmall.gif HTTP/1.0\" 200 3635', '163.206.104.17 - - [24/Jul/1995:07:35:20 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 304 0', 'fsv-ckyriss.unl.edu - - [24/Jul/1995:09:13:17 -0400] \"GET / HTTP/1.0\" 200 7071', '170.181.16.34 - - [24/Jul/1995:09:26:57 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'proxy0.research.att.com - - [24/Jul/1995:12:00:07 -0400] \"GET /history/apollo/apollo-1/images/ HTTP/1.0\" 200 1190', 'pr19.bsvc.berkeley.edu - - [24/Jul/1995:15:28:46 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 200 234', '204.126.162.140 - - [24/Jul/1995:16:04:50 -0400] \"GET /history/gemini/gemini-vii/gemini-vii-patch-small.gif HTTP/1.0\" 200 22852', 'inrete.alpcom.it - - [24/Jul/1995:17:01:59 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 304 0', 'www-b3.proxy.aol.com - - [24/Jul/1995:17:16:00 -0400] \"GET /shuttle/countdown/count70.gif HTTP/1.0\" 200 46573', 'francis.austin.asc.slb.com - - [24/Jul/1995:19:56:11 -0400] \"GET /history/apollo/apollo-10/ HTTP/1.0\" 200 1732', 'nitehawk.maf.nasa.gov - - [25/Jul/1995:02:08:50 -0400] \"GET /shuttle/technology/images/launch_sites_8-small.gif HTTP/1.0\" 200 74267', 'line001.pg.mindlink.net - - [25/Jul/1995:02:14:19 -0400] \"GET /shuttle/missions/sts-70/images/images.html HTTP/1.0\" 200 8657', 'corning.com - - [25/Jul/1995:13:06:28 -0400] \"GET /shuttle/countdown/count70.gif HTTP/1.0\" 200 46573', 'ppp98.cybernet.dk - - [25/Jul/1995:15:18:58 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713', 'brick.bpa.gov - - [25/Jul/1995:16:41:26 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 200 363', 'unni.tn.cornell.edu - - [25/Jul/1995:17:31:24 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 200 5866', '130.191.147.106 - - [25/Jul/1995:22:25:58 -0400] \"GET /history/apollo/as-201/as-201-patch-small.gif HTTP/1.0\" 200 16184', 'igate.ska.com - - [26/Jul/1995:07:56:52 -0400] \"GET /shuttle/missions/sts-71/images/KSC-95EC-0911.jpg HTTP/1.0\" 200 45966', 'mnet.den.mmc.com - - [26/Jul/1995:10:05:54 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', 'n868896.ksc.nasa.gov - - [26/Jul/1995:15:01:51 -0400] \"GET /mdss/s_md-2.gif HTTP/1.0\" 200 15528', 'kslip1.apl.jhu.edu - - [26/Jul/1995:22:00:02 -0400] \"GET /history/mercury/mercury.html HTTP/1.0\" 200 1871', 'kotah.tfs.com - - [26/Jul/1995:22:18:09 -0400] \"GET /shuttle/missions/sts-70/images/DSC-95EC-0006.jpg HTTP/1.0\" 200 488494', 'spiral_b.secom-sis.co.jp - - [27/Jul/1995:06:04:15 -0400] \"GET /images/launchpalms-small.gif HTTP/1.0\" 200 11473', '161.13.3.169 - - [27/Jul/1995:09:50:52 -0400] \"GET /history/apollo/images/footprint-small.gif HTTP/1.0\" 200 18149', 'joan.cadence.com - - [27/Jul/1995:10:08:01 -0400] \"GET /history/apollo/images/apollo-logo1.gif HTTP/1.0\" 200 1173', 'lmac18.jsc.nasa.gov - - [27/Jul/1995:16:06:55 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'igate.uswest.com - - [27/Jul/1995:18:22:10 -0400] \"GET /history/apollo/apollo-13/apollo-13-patch-small.gif HTTP/1.0\" 200 12859', '128.159.128.11 - - [27/Jul/1995:18:56:08 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 200 234', 'ix-pl5-08.ix.netcom.com - - [28/Jul/1995:03:34:05 -0400] \"GET /elv/DELTA/delta.gif HTTP/1.0\" 200 2244', 'j11.glg3.jaring.my - - [28/Jul/1995:12:13:00 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', 'pm2_10.digital.net - - [28/Jul/1995:12:45:50 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 304 0']\n"
     ]
    }
   ],
   "source": [
    "# Make sure you know how much data 0.01% of your dataset is! \n",
    "#It might look like a small fraction, but in the Big Data world \n",
    "#even that might be too much for your local computer!\n",
    "\n",
    "local_sample = \\\n",
    "nasa_logs.sample(withReplacement=False,fraction=0.0001).\\\n",
    "collect()\n",
    "\n",
    "print(local_sample)\n",
    "\n",
    "#withReplacement=False ensures unique choices in sampling!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb60fd0-d533-42b2-baba-de95fdca16f6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Web server logs like this are called 'semi-structured' for a reason: we can be pretty sure that every line will be formatted the same way. This means every element in each of our Partitions looks pretty much the same after our first step. We can be confident that the same unwanted characters ended up inside the elements of all partitions of our RDD. So our next step takes care of removing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3de336a1-8093-42f2-b43b-8088ee66d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning: remove the unwanted characters\n",
    "# The dictionary maps three unwanted characters ([ ], and \") to empty strings ('')\n",
    "\n",
    "replacement_dict = {\"[\":'',\"]\":'',\"\\\"\":''}\n",
    "\n",
    "nasa_logs_structured = nasa_logs.map(lambda line : line.split(\" \")).\\\n",
    "filter(lambda line : len(line)==10).\\\n",
    "map(lambda line : [element.translate(str.maketrans(replacement_dict)) \\\n",
    "               \tfor element in line])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dbc0e5-9a29-40d1-9312-09c2fac51c0a",
   "metadata": {},
   "source": [
    "In summary, this code cleaned the data by removing square brackets and double quotes from each element in lines that have exactly 10 elements. \n",
    "\n",
    "* The translate() method returns a string where some specified characters are replaced with the character described in a dictionary, or in a mapping table.\n",
    "* The str.maketrans(replacement_dict) part creates a translation table that maps the keys (characters) to their corresponding values (empty strings)\n",
    "* The element.translate(...) call uses this translation table to remove the characters specified in the replacement_dict keys from the string element.\n",
    "\n",
    "Ok, so now our RDD has the following elements: \n",
    "\n",
    "IP/NAME_OF_ORIGIN \n",
    "DATE/TIME, TIMEZONE\n",
    " REQUEST_METHOD\n",
    " RESOURCE_REQUESTED\n",
    " PROTOCOL\n",
    " STATUS_CODE, SIZE_OF_RESOURCE\n",
    "\n",
    "That looks pretty much like a CSV (or a Dataframe) a Data Scientist could work with! We aim to take advantage of our now-structured dataset and see if we can do a bit of Data Science using the RDD API directly. Let's find out where most requests to the NASA web server came from on our dataset. To do this, let's do a little bit of Map-Reduce.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09c2e1e7-ed5f-4cd4-809d-4f906202bc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('199.72.81.55', 1),\n",
       " ('unicomp6.unicomp.net', 1),\n",
       " ('199.120.110.21', 1),\n",
       " ('burger.letters.com', 1),\n",
       " ('199.120.110.21', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take each line of our structured log and return a Key-Value Pair\n",
    "\n",
    "nasa_logs_structured.map(lambda line : (line[0],1) ).take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982a2fd3-2c32-467a-82e7-77a2d24e7806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17572, 'piweba3y.prodigy.com'),\n",
       " (11591, 'piweba4y.prodigy.com'),\n",
       " (9868, 'piweba1y.prodigy.com'),\n",
       " (7852, 'alyssa.prodigy.com'),\n",
       " (7573, 'siltb10.orl.mmc.com')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify and return the five most frequent encounters \n",
    "# like the count program, we create a tuple containing the encounters and a count of 1 \n",
    "# representing its initial occurrence, then compute the total count.\n",
    "\n",
    "nasa_logs_structured.map(lambda line : (line[0],1) ).\\\n",
    "reduceByKey(lambda a,b : a+b).\\\n",
    "map(lambda kv_pair : (kv_pair[1],kv_pair[0])).\\\n",
    "sortByKey(ascending=False).take(5)\n",
    "\n",
    "# The second map() transforms the DataFrame to have the count as the first element \n",
    "# for sorting purposes and the word as the second element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6e5544-d166-4b46-abe3-7d88d1d80243",
   "metadata": {},
   "source": [
    "\n",
    "Exercise 3.1 - Word count in NASA log\n",
    "\n",
    "If we take the element containing NASA's website resource names and we replace the \"/\"s and \".\"s by \" \"s, we sort of get words. Write a word count program to find the top 5 most frequent words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df50e6dd-2aee-4ed5-8915-db3d195f329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step essentially should splits the resource name based on\n",
    "# / and . characters and treats them as word separators.\n",
    "# The result should be a new DataFrame containing these \"cleaned-up\" website resource names.\n",
    "\n",
    "words = nasa_logs_structured.\\\n",
    "map(lambda line : line[6].\\\n",
    "    replace('/',' ').\\\n",
    "    replace('.',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2279c35-f5db-4c0b-bb3f-b30a9ff40d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1028316, 'gif'),\n",
       " (878642, 'images'),\n",
       " (655862, 'shuttle'),\n",
       " (417861, 'html'),\n",
       " (404042, 'missions')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This step effectively should create a new DataFrame\n",
    "# where each row is a single word extracted from the website resource names.\n",
    "# Use flatMap() method to flattening the list of words into a single level.\n",
    "# Then use a map() transformation to create your count tuple\n",
    "# Finally use a reduceByKey action to calculate the total count for each word\n",
    "\n",
    "words.\\\n",
    "flatMap(lambda line: line.split(\" \")).\\\n",
    "filter(lambda word: word).\\\n",
    "map(lambda word : (word, 1)).\\\n",
    "reduceByKey(lambda a,b : a+b).\\\n",
    "map(lambda kv_pair : (kv_pair[1],kv_pair[0])).\\\n",
    "sortByKey(ascending=False).take(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a63e098-3ac9-428c-a15f-be208820325a",
   "metadata": {},
   "source": [
    "\n",
    "Reading a CSV file with Core Spark API (RDD API):\n",
    "\n",
    "The RDD API is very powerful, but on its own it has some serious limitations. Ironically, one of its biggest limitations is its usefulness on structured data... like CSV files.\n",
    "\n",
    "We had caught a glimpse of that on the NASA website example, but now let's look at a real-life CSV to illustrate this and introduce the Pandas on Spark API - a powerful API for which the RDD API can work as a beautiful complement.\n",
    "\n",
    "The file below contains data about all pieces owned/maintained by the Metropolitan Museum of Art in New York City. As we've seen before, the RDD API only allows us to load it as a plain text file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57d14c57-da57-461f-ad1b-07be147fbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sc.textFile('data/surveys.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "113c168f-f3e5-4e28-88ff-fae6f57fac7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35550"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00ea7155-cb76-44ff-a449-82145081a653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['record_id,month,day,year,plot_id,species_id,sex,hindfoot_length,weight']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9cdd59a-ec24-4099-a37d-2be7c5e478ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_split = sample_data.map(lambda line : line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16e058dc-d4ba-4c7f-9b60-bcd13ada33f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['record_id',\n",
       "  'month',\n",
       "  'day',\n",
       "  'year',\n",
       "  'plot_id',\n",
       "  'species_id',\n",
       "  'sex',\n",
       "  'hindfoot_length',\n",
       "  'weight'],\n",
       " ['1', '7', '16', '1977', '2', 'NL', 'M', '32', '']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_split.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6760fc08-1bda-48a1-81c5-c93a944bfc0f",
   "metadata": {},
   "source": [
    "Spark Pandas API:\n",
    "\n",
    "The Spark Core RDD API is a powerful tool for operating on very large Data. However, the RDD API and its Functional Programming flavor are not for everyone. Most people dealing with heavy-duty data analytics problems are used to far more structured data types. Whether they're R users or Python users, data people love data that is in a tabular format - a Table in database or a DataFrame in R or Pandas. In most data analysis situations, it is important to be able to mimic some functionality and design choices from the Pandas package as one of the most powerful python packages to analyze data. To cater to this particular user base, Spark maintainers have introduced a new API in Spark v3: Pandas on Spark. As the name suggests, the idea behind this API is to reproduce the user experience from the Pandas package with as many of its methods and operators as possible, but on a very large scale distributed DataFrames. Note that as this API is actively being developed, you might encounter some errors with some functions. Usually, downgrading PySpark or Pandas version can fix those issues.\n",
    "\n",
    "To get started, first let's import the module pyspark.pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7d50dff-80d4-4c17-a33f-33d6cdeda68e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yemon\\anaconda33\\Lib\\site-packages\\pyspark\\pandas\\__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#import PySpark Pandas API\n",
    "#ignore the warning!\n",
    "\n",
    "import pyspark.pandas as ps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff3d838-248f-4082-a741-2fda4054330d",
   "metadata": {},
   "source": [
    "A handy way of using Pandas on Spark is by converting an actual Pandas DataFrame into a Pandas on Spark DataFrame. In this scenario, you would have a regular Pandas DataFrame, created without any calls to Spark that you wish to perform work on in a parallelized or even distributed fashion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5fe4534-5e55-4701-8c71-953fa792b6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's create a Pandas dataframe from a CSV file and then convert it to Pandas on Spark DataFrame\n",
    "import pandas as pd\n",
    "survey_df_local = pd.read_csv(\"data/surveys.csv\")\n",
    "type(survey_df_local)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a588824-0c4d-44e0-9760-92d298566ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>hindfoot_length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>2</td>\n",
       "      <td>NL</td>\n",
       "      <td>M</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>3</td>\n",
       "      <td>NL</td>\n",
       "      <td>M</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>2</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>7</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>3</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id  month  day  year  plot_id species_id sex  hindfoot_length  \\\n",
       "0          1      7   16  1977        2         NL   M             32.0   \n",
       "1          2      7   16  1977        3         NL   M             33.0   \n",
       "2          3      7   16  1977        2         DM   F             37.0   \n",
       "3          4      7   16  1977        7         DM   M             36.0   \n",
       "4          5      7   16  1977        3         DM   M             35.0   \n",
       "\n",
       "   weight  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's look at the data:\n",
    "survey_df_local.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46e249a-a1da-4579-9187-78619eae462d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.pandas.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's create a Spark DataFrame from a Pandas DataFrame!\n",
    "\n",
    "survey_df_distributed = ps.from_pandas(survey_df_local)\n",
    "type(survey_df_distributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a3924-aaab-4c2f-8396-66184c25215c",
   "metadata": {},
   "source": [
    "Now we have a parallelized or distributed DataFrame that looks and behaves just like a regular Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5781840-abb9-4dd7-9ff8-336a7b09a611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>hindfoot_length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>2</td>\n",
       "      <td>NL</td>\n",
       "      <td>M</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>3</td>\n",
       "      <td>NL</td>\n",
       "      <td>M</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>2</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>7</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>3</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id  month  day  year  plot_id species_id sex  hindfoot_length  weight\n",
       "0          1      7   16  1977        2         NL   M             32.0     NaN\n",
       "1          2      7   16  1977        3         NL   M             33.0     NaN\n",
       "2          3      7   16  1977        2         DM   F             37.0     NaN\n",
       "3          4      7   16  1977        7         DM   M             36.0     NaN\n",
       "4          5      7   16  1977        3         DM   M             35.0     NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at this DataFrame using some familiar methods: first head()\n",
    "survey_df_distributed.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90dd09e-2429-4206-b93a-58b95907bfc8",
   "metadata": {},
   "source": [
    "Next, we will go through a few examples of how to use Pandas on Spark DataFrame. Accessing columns and rows, as well as slicing a DataFrame works just like in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93dffa16-c4ed-4802-bfc4-2ca02be88a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   NaN\n",
       "1   NaN\n",
       "2   NaN\n",
       "3   NaN\n",
       "4   NaN\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "survey_df_pandas = survey_df_distributed # make a copy of the Spark DataFrame\n",
    "\n",
    "# Access columns by name with two different syntaxes:\n",
    "survey_df_pandas['weight'].head()\n",
    "#survey_df_pandas.weight.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf780b88-ba9f-4c14-a0c7-fa6513af0463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "record_id            11\n",
       "month                 7\n",
       "day                  16\n",
       "year               1977\n",
       "plot_id               5\n",
       "species_id           DS\n",
       "sex                   F\n",
       "hindfoot_length    53.0\n",
       "weight              NaN\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the .iloc() method to access a row by index\n",
    "survey_df_pandas.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d1e8912-e363-4a07-adc8-1ef355d68ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>hindfoot_length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>7</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>37.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>4</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>35.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>8</td>\n",
       "      <td>DO</td>\n",
       "      <td>F</td>\n",
       "      <td>32.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>7</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>4</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>35.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    record_id  month  day  year  plot_id species_id sex  hindfoot_length  weight\n",
       "63         64      8   19  1977        7         DM   M             37.0    48.0\n",
       "65         66      8   19  1977        4         DM   F             35.0    46.0\n",
       "67         68      8   19  1977        8         DO   F             32.0    52.0\n",
       "78         79      8   19  1977        7         DM   F             34.0    42.0\n",
       "81         82      8   19  1977        4         DM   F             35.0    41.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use conditionals to find subsets of a DataFrame that match a condition\n",
    "survey_df_pandas[survey_df_pandas.weight > 40].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db3399b1-a88a-4a20-918a-16139bce80c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>hindfoot_length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35549.000000</td>\n",
       "      <td>35549.000000</td>\n",
       "      <td>35549.000000</td>\n",
       "      <td>35549.000000</td>\n",
       "      <td>35549.000000</td>\n",
       "      <td>31438.000000</td>\n",
       "      <td>32283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17775.000000</td>\n",
       "      <td>6.474022</td>\n",
       "      <td>16.105966</td>\n",
       "      <td>1990.475231</td>\n",
       "      <td>11.397001</td>\n",
       "      <td>29.287932</td>\n",
       "      <td>42.672428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10262.256696</td>\n",
       "      <td>3.396583</td>\n",
       "      <td>8.256691</td>\n",
       "      <td>7.493355</td>\n",
       "      <td>6.799406</td>\n",
       "      <td>9.564759</td>\n",
       "      <td>36.631259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1977.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8888.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17772.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26661.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35549.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>280.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          record_id         month           day          year       plot_id  hindfoot_length        weight\n",
       "count  35549.000000  35549.000000  35549.000000  35549.000000  35549.000000     31438.000000  32283.000000\n",
       "mean   17775.000000      6.474022     16.105966   1990.475231     11.397001        29.287932     42.672428\n",
       "std    10262.256696      3.396583      8.256691      7.493355      6.799406         9.564759     36.631259\n",
       "min        1.000000      1.000000      1.000000   1977.000000      1.000000         2.000000      4.000000\n",
       "25%     8888.000000      4.000000      9.000000   1984.000000      5.000000        21.000000     20.000000\n",
       "50%    17772.000000      6.000000     16.000000   1990.000000     11.000000        32.000000     37.000000\n",
       "75%    26661.000000      9.000000     23.000000   1997.000000     17.000000        36.000000     48.000000\n",
       "max    35549.000000     12.000000     31.000000   2002.000000     24.000000        70.000000    280.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics\n",
    "survey_df_pandas.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "081fd0da-5a73-44d9-a283-8d86583ff7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.672428212991356"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# location measures\n",
    "survey_df_pandas.weight.mean()\n",
    "#survey_df_pandas.weight.median()\n",
    "#survey_df_pandas.weight.quantile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0425aa86-e2b3-4a1a-9d9e-989ccad88f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341.8491706942696"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dispersion measures:\n",
    "#survey_df_pandas.weight.std()\n",
    "survey_df_pandas.weight.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d71f7-8dd4-4ca8-8a67-0c35943b696f",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "* Parallelizing a DataFrame does not necessarily mean any arbitrary operation will run faster. In general, you can expect Pandas on Spark to outperform Pandas as the size of a DataFrame grows, even if you are running PySpark on a single node. That being said, you should always reason about scalability before choosing to parallelize work over multiple cores, or multiple nodes. See this article for more about scalability: https://docs.alliancecan.ca/wiki/Scalability\n",
    "\n",
    "* Pandas on Spark is not a 100% perfect clone of Pandas - some Pandas functionalities have not yet been implemented, some probably never will be, and Pandas on Spark have a few features that do not exist on Pandas. See the complete API reference for more details: https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b2a154-e016-4ec1-83a5-1ab717a4a2d0",
   "metadata": {},
   "source": [
    "Exercise 4.1 \n",
    "\n",
    "Use pandas on Spark API:\n",
    "\n",
    "* Create a parallel query that finds all rows with a weight value greater than 50 and hindfoot_length larger than 52, and then calculate the summary statistics of these rows.\n",
    "\n",
    "* Hint: You can use where() method to introduce two different conditions in your search and dropna() method to remove rows with missing values in weight or hindfoot_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efb0a777-e9ad-4536-a720-b22411307cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>hindfoot_length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8102.560847</td>\n",
       "      <td>6.391534</td>\n",
       "      <td>13.232804</td>\n",
       "      <td>1983.380952</td>\n",
       "      <td>7.328042</td>\n",
       "      <td>53.534392</td>\n",
       "      <td>137.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5436.685915</td>\n",
       "      <td>3.163141</td>\n",
       "      <td>7.784244</td>\n",
       "      <td>3.902108</td>\n",
       "      <td>5.801532</td>\n",
       "      <td>0.866107</td>\n",
       "      <td>17.657543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>392.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1977.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3914.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1981.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6844.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1982.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12973.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28927.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>172.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          record_id       month         day         year     plot_id  hindfoot_length      weight\n",
       "count    189.000000  189.000000  189.000000   189.000000  189.000000       189.000000  189.000000\n",
       "mean    8102.560847    6.391534   13.232804  1983.380952    7.328042        53.534392  137.740741\n",
       "std     5436.685915    3.163141    7.784244     3.902108    5.801532         0.866107   17.657543\n",
       "min      392.000000    1.000000    1.000000  1977.000000    1.000000        53.000000   51.000000\n",
       "25%     3914.000000    4.000000    7.000000  1981.000000    2.000000        53.000000  129.000000\n",
       "50%     6844.000000    6.000000   12.000000  1982.000000    8.000000        53.000000  140.000000\n",
       "75%    12973.000000    9.000000   20.000000  1987.000000    9.000000        54.000000  150.000000\n",
       "max    28927.000000   12.000000   31.000000  1998.000000   22.000000        58.000000  172.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exercise 4.1 Solution\n",
    "\n",
    "filtered_df = (\n",
    "    survey_df_pandas\n",
    "    .where((survey_df_pandas.weight > 50) & (survey_df_pandas.hindfoot_length > 52))\n",
    "    .dropna(subset=[\"weight\", \"hindfoot_length\"])  # Remove rows with missing values in weight or hindfoot_length\n",
    "  \n",
    ")\n",
    "filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f3511-cf14-41e0-99d4-ed21b885d36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
