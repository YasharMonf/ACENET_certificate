{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e71ab2-d8ea-477f-b8de-a39c7bf4dd1c",
   "metadata": {},
   "source": [
    "So far we've used toy examples to introduce the RDD API along with a few of its Transformations and Actions. Now let's look at a more real-life example: let's wrangle a fairly big \"semi-structured\" file and turn it into something a Data Scientist would be ready to work with. In fact, let's ask a few Data Science-y questions of this data and use Spark itself to answer them while we are at it!\n",
    "\n",
    "In order to continue with this lesson, first download the required data files and put it in your data folder inside your working directory.\n",
    "\n",
    "This example file is a standard Apache web server log. It's the logs from a month's worth of requests to NASA's website, in the distant year of 1995, combined into one fairly big file to be more specific.\n",
    "\n",
    "This log contains the following information:\n",
    "\n",
    "* The IP Address or the DNS name performing a request\n",
    "* A time stamp of the form: \"dd/Mon/YYYY:hh:mm:ss Timezone\"\n",
    "* The request type (HTTP verb), the resource being requested and the Protocol used\n",
    "* The code returned by the server (200 OK, 400 Not Found etc...)\n",
    "* The Size of the resource being requested\n",
    "\n",
    "We will use the textFile method to read in this file. This, like the parallelize method, turns the data inside this file into an RDD. There are two important things you need to know about this method: \n",
    "\n",
    "* In a real-life Spark Cluster, the location of the file (the argument you will pass to textFile) must be visible/accessible to all nodes of the Cluster. In practice, a lot of the time this location will be a path on a Hadoop Distributed File System (HDFS), but this can be any Network File System, or a location mounted on all nodes, or Amazon S3... as long as it's visible and accessible on all nodes! \n",
    "\n",
    "* This method turns each line of the input file into an element in a Partition. So ,no matter what the format of the file is, when it gets turned into an RDD, each line (as delimited by a newline a.k.a. \"\\n\") becomes an element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6658ed1-af8d-4d81-8fb0-f9826e7e3e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's import pyspark, initialize a Spark connection\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "#Let's read NASA logs as a textfile into a variable and find out the type of variable we defined here\n",
    "nasa_logs = sc.textFile('data/NASA_access_log_Jul95.gz')\n",
    "type(nasa_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcfe16b-3641-45ba-92a2-c4b4c53217e4",
   "metadata": {},
   "source": [
    "The first step in any data problem is to look at the data to get a sense of what we are dealing with. A good practice is to find out how many elements we have to get a sense of what we are dealing with. The RDD API has the count method for that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14c44f2-d7ba-4984-805d-3a6ab452aac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1891715"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use count() method to see how many elements (lines) are in the NASA logs\n",
    "nasa_logs.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f79a7-a68f-4252-ac4e-872e4df55410",
   "metadata": {},
   "source": [
    "The RDD API has the take Action, that brings a number of elements (remember, an element here is a line of the original file) back to the Driver so we can see them. The important thing here is to be careful not to bring too many elements back to Driver and blow up its memory capacity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8333b5e-e6f4-4cf2-a307-a9dc6fd2a1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use take() action to bring a number of elements from Cluster back to the Driver!\n",
    "nasa_logs.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05ca7ba-3c1a-4128-8160-aac8dd22bb7f",
   "metadata": {},
   "source": [
    "Now that we can see what the data looks like, a reasonable first step seems to be to split the data on the \" \" (space) character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be64964-6234-4768-a29d-aedfb2bb3031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['199.72.81.55',\n",
       "  '-',\n",
       "  '-',\n",
       "  '[01/Jul/1995:00:00:01',\n",
       "  '-0400]',\n",
       "  '\"GET',\n",
       "  '/history/apollo/',\n",
       "  'HTTP/1.0\"',\n",
       "  '200',\n",
       "  '6245']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data on space characters\n",
    "nasa_logs.map(lambda line : line.split(\" \")).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bfc5f5-0d20-4283-b413-e3cf7bce1d42",
   "metadata": {},
   "source": [
    "Next, for the sake of this example, let's say we are not interested in lines where there is data missing. In other words, we are only interested in lines that have all 10 elements. We will use the filter method to filter any lines that don't have all 10 elements out of our RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b148a1f-fb8d-42a7-8693-1575d4f77da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1886891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data and count the lines that have 10 exactly elements\n",
    "\n",
    "nasa_logs.map(lambda line : line.split(\" \")).\\\n",
    "filter(lambda line : len(line)==10).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8b0c8-8490-47b5-9f63-66fcc463a921",
   "metadata": {},
   "source": [
    "\n",
    "This line of code in PySpark performs a series of operations to count the number of lines in the \n",
    "nasa_logs RDD that have exactly 10 words (or elements) separated by spaces.\n",
    "\n",
    "You might be asking yourself whether using the take method all the time to check if we are doing things right is the best practice... and the answer is no. Everytime you call it, you are computing a new RDD and thus having the Spark Cluster do work for you. In real-life you will rarely have a Cluster all for yourself, so you should expect your computations to get queued and competing for resources with other users. in this scenario, minimizing the amount of times you move things back and forth between the Driver and the Executors is a good idea.\n",
    "\n",
    "So in practice, one approach would be to use the RDD API method sample to extract a sample of your data to examine in the driver and figure out what you need to do before farming out computations to the cluster. The take method also works here, but getting a random sample (using sample() method) instead of the first N elements of your RDD is almost always a better plan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcaf0371-dc63-41d6-a7b1-970f47ca030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pm1-09.magicnet.net - - [01/Jul/1995:14:02:01 -0400] \"GET /images/ksclogosmall.gif HTTP/1.0\" 200 3635', 'ad03-027.compuserve.com - - [01/Jul/1995:16:20:57 -0400] \"GET /shuttle/missions/sts-78/mission-sts-78.html HTTP/1.0\" 200 4378', 'line10.pm1.abb.mindlink.net - - [01/Jul/1995:17:07:53 -0400] \"GET /images/launchmedium.gif HTTP/1.0\" 200 11853', 'slsyd2p64.ozemail.com.au - - [01/Jul/1995:19:34:46 -0400] \"GET /history/history.html HTTP/1.0\" 304 0', 'dd08-018.compuserve.com - - [01/Jul/1995:20:49:11 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 200 234', 'cslip6.irb.hr - - [01/Jul/1995:22:00:32 -0400] \"GET /shuttle/missions/sts-71/images/KSC-95EC-0874.txt HTTP/1.0\" 200 541', 'dialup1.starg.com - - [02/Jul/1995:01:03:06 -0400] \"GET /facilities/lc39a.html HTTP/1.0\" 200 7008', 'dyn-267.direct.ca - - [02/Jul/1995:01:56:00 -0400] \"GET /history/apollo/apollo.html HTTP/1.0\" 200 3258', 'bobjoy.pr.mcs.net - - [02/Jul/1995:16:56:37 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', 'stevem.aladdin.co.uk - - [02/Jul/1995:17:52:10 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 69063', 'ip180.tull.edge.net - - [02/Jul/1995:19:37:10 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985', 'slip4063.sirius.com - - [03/Jul/1995:02:14:35 -0400] \"GET /cgi-bin/imagemap/countdown?332,273 HTTP/1.0\" 302 98', '130.225.253.190 - - [03/Jul/1995:06:44:09 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985', '155.31.20.77 - - [03/Jul/1995:07:02:39 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 200 234', 'a-206-15.sp.neu.edu - - [03/Jul/1995:11:13:00 -0400] \"GET /cgi-bin/imagemap/countdown?49,151 HTTP/1.0\" 302 100', '170.180.169.178 - - [03/Jul/1995:12:26:21 -0400] \"GET / HTTP/1.0\" 200 7074', '204.155.149.77 - - [03/Jul/1995:13:32:46 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'zuul.lcp.com - - [03/Jul/1995:14:38:54 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 200 5866', '128.159.122.50 - - [03/Jul/1995:15:50:32 -0400] \"GET /finance/other.htm HTTP/1.0\" 200 2884', 'wxs4-16.worldaccess.nl - - [03/Jul/1995:16:04:18 -0400] \"GET /shuttle/countdown/count.gif HTTP/1.0\" 200 40310', 'dial5.phoenix.net - - [03/Jul/1995:18:27:58 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 200 363', 'sea-ts1-p20.wolfe.net - - [03/Jul/1995:19:51:05 -0400] \"GET /history/gemini/gemini-vi-a/gemini-vi-a-patch-small.gif HTTP/1.0\" 200 20882', 'cs1-02.mah.ptd.net - - [03/Jul/1995:19:59:05 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 200 669', 'vis.caltech.edu - - [03/Jul/1995:21:24:22 -0400] \"GET /shuttle/countdown/count.gif HTTP/1.0\" 200 40310', 'lonestar1.comsys.rockwell.com - - [03/Jul/1995:23:06:49 -0400] \"GET /shuttle/countdown/lps/back.gif HTTP/1.0\" 200 1289', '128.230.4.244 - - [04/Jul/1995:02:26:40 -0400] \"GET /shuttle/missions/sts-77/sts-77-patch-small.gif HTTP/1.0\" 200 4179', 'ntigate.nt.com - - [04/Jul/1995:09:46:43 -0400] \"GET /shuttle/missions/sts-71/mission-sts-71.html HTTP/1.0\" 304 0', 'port13.ts1.msstate.edu - - [04/Jul/1995:20:47:28 -0400] \"GET /history/apollo/apollo-13/ HTTP/1.0\" 200 1732', 'dialup-239.austin.io.com - - [04/Jul/1995:21:25:24 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 200 5866', 'bs3051.lib.shizuoka.ac.jp - - [05/Jul/1995:06:04:49 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 200 5866', 'ns.rmc.com - - [05/Jul/1995:12:18:33 -0400] \"GET /shuttle/countdown/count.gif HTTP/1.0\" 200 40310', 'dyer.npt.nuwc.navy.mil - - [05/Jul/1995:14:10:49 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713', '198.123.47.7 - - [05/Jul/1995:14:25:03 -0400] \"GET /shuttle/missions/sts-71/images/KSC-95EC-0911.gif HTTP/1.0\" 200 31242', '192.190.9.50 - - [05/Jul/1995:16:04:42 -0400] \"GET / HTTP/1.0\" 200 7074', 'jobrien.datasys.swri.edu - - [05/Jul/1995:16:50:03 -0400] \"GET /icons/text.xbm HTTP/1.0\" 200 527', '129.130.115.19 - - [05/Jul/1995:17:22:59 -0400] \"GET /shuttle/missions/missions.html HTTP/1.0\" 200 8677', 'jove.acs.unt.edu - - [05/Jul/1995:22:44:09 -0400] \"GET /shuttle/resources/orbiters/atlantis.html HTTP/1.0\" 200 7025', 'as2b-p07.mts.net - - [06/Jul/1995:00:22:42 -0400] \"GET /shuttle/missions/sts-71/mission-sts-71.html HTTP/1.0\" 200 12722', 'sappho1.u.washington.edu - - [06/Jul/1995:00:27:48 -0400] \"GET /history/apollo/apollo.html HTTP/1.0\" 200 3258', 'dcpc15.pa-x.dec.com - - [06/Jul/1995:10:23:46 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', 'mceldowney.usc.edu - - [06/Jul/1995:16:45:53 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713', 'ix-akr-oh2-09.ix.netcom.com - - [06/Jul/1995:20:39:30 -0400] \"GET /history/apollo/images/footprint-logo.gif HTTP/1.0\" 200 4209', 'piweba2y.prodigy.com - - [06/Jul/1995:22:15:15 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 200 669', '128.194.200.96 - - [06/Jul/1995:22:47:04 -0400] \"GET /images/ksclogosmall.gif HTTP/1.0\" 304 0', 'n868386.ksc.nasa.gov - - [07/Jul/1995:07:44:10 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', '128.227.104.211 - - [07/Jul/1995:10:44:53 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 200 669', '128.227.104.211 - - [07/Jul/1995:10:46:02 -0400] \"GET /shuttle/missions/missions.html HTTP/1.0\" 200 8677', 'vonduhn.lottery.ohio.gov - - [07/Jul/1995:12:14:24 -0400] \"GET /icons/image.xbm HTTP/1.0\" 200 509', 'webgate1.mot.com - - [07/Jul/1995:12:33:23 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3998', '204.138.176.113 - - [07/Jul/1995:16:45:01 -0400] \"GET /history/apollo/apollo-13/images/index.gif HTTP/1.0\" 200 99942', 'dd10-031.compuserve.com - - [07/Jul/1995:17:31:01 -0400] \"GET /shuttle/missions/sts-71/sts-71-patch-small.gif HTTP/1.0\" 200 12054', 'ix-hou8-07.ix.netcom.com - - [07/Jul/1995:19:15:07 -0400] \"GET /history/apollo/apollo-13/apollo-13.html HTTP/1.0\" 200 18114', 'piweba4y.prodigy.com - - [07/Jul/1995:19:55:54 -0400] \"GET /shuttle/missions/sts-66/mission-sts-66.html HTTP/1.0\" 200 173980', 'xyplex4-1-16.ucs.indiana.edu - - [07/Jul/1995:22:52:48 -0400] \"GET /software/winvn/wvsmall.gif HTTP/1.0\" 200 13372', 'piweba4y.prodigy.com - - [07/Jul/1995:23:01:22 -0400] \"GET /shuttle/countdown/lps/fr.gif HTTP/1.0\" 200 30232', '204.158.58.1 - - [08/Jul/1995:00:57:08 -0400] \"GET /history/gemini/gemini.html HTTP/1.0\" 200 2522', 'callandor.cybercash.com - - [08/Jul/1995:01:46:44 -0400] \"GET /history/apollo/images/footprint-logo.gif HTTP/1.0\" 304 0', 'roger12.ecn.purdue.edu - - [08/Jul/1995:15:12:57 -0400] \"GET /images/ksclogosmall.gif HTTP/1.0\" 200 3635', 'async_603.italnet.it - - [08/Jul/1995:16:42:19 -0400] \"GET /shuttle/technology/sts-newsref/srb.html HTTP/1.0\" 200 49152', 'frigga.wwic.com - - [08/Jul/1995:17:42:17 -0400] \"GET /icons/text.xbm HTTP/1.0\" 200 527', 'chaos.michsb.trw.com - - [09/Jul/1995:09:35:26 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 200 669', 'ttyc9ip.magic.mb.ca - - [09/Jul/1995:11:14:26 -0400] \"GET /shuttle/missions/sts-64/mission-sts-64.html HTTP/1.0\" 200 58275', 'dd06-054.compuserve.com - - [09/Jul/1995:18:22:36 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713', 'cust61.max1.seattle.wa.ms.uu.net - - [09/Jul/1995:23:17:18 -0400] \"GET /history/apollo/images/footprint-logo.gif HTTP/1.0\" 200 4209', '163.205.1.45 - - [10/Jul/1995:09:56:16 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 304 0', 'gate.cfe.gob.mx - - [10/Jul/1995:14:53:32 -0400] \"GET /shuttle/missions/sts-71/sts-71-patch-small.gif HTTP/1.0\" 304 0', 'netport-8.iu.net - - [10/Jul/1995:15:21:08 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713', 'h97-152.ccnet.com - - [10/Jul/1995:23:53:48 -0400] \"GET /shuttle/countdown/count70.gif HTTP/1.0\" 200 48511', 'gn2.getnet.com - - [11/Jul/1995:02:53:15 -0400] \"GET /images/landing.jpg HTTP/1.0\" 200 65536', 'ip162.tus.primenet.com - - [11/Jul/1995:03:29:38 -0400] \"GET /history/apollo/apollo-13/apollo-13-patch-small.gif HTTP/1.0\" 200 12859', 'rzurs4.unizh.ch - - [11/Jul/1995:08:05:34 -0400] \"GET /shuttle/countdown/countdown70.html HTTP/1.0\" 200 4247', 'bill.ksc.nasa.gov - - [11/Jul/1995:08:56:43 -0400] \"GET /htbin/cdt_main.pl HTTP/1.0\" 200 3585', '128.159.124.108 - - [11/Jul/1995:12:19:00 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 304 0', 'worm.hooked.net - - [11/Jul/1995:14:41:51 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713', '128.146.203.176 - - [11/Jul/1995:15:45:18 -0400] \"GET /history/apollo/apollo-1/images/67HC31.gif HTTP/1.0\" 200 73728', '192.100.230.168 - - [11/Jul/1995:19:54:27 -0400] \"GET /shuttle/missions/sts-67/images/KSC-95EC-0391.jpg HTTP/1.0\" 200 49152', 'piweba4y.prodigy.com - - [11/Jul/1995:20:18:20 -0400] \"GET /history/apollo/apollo-13/apollo-13.html HTTP/1.0\" 200 18114', 'ip184.lax.primenet.com - - [12/Jul/1995:03:46:40 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 200 3031', 'jhurd.pdial.interpath.net - - [12/Jul/1995:09:48:40 -0400] \"GET /shuttle/missions/sts-70/sts-70-patch-small.gif HTTP/1.0\" 200 5026', 'lis013.lis.wwu.edu - - [12/Jul/1995:11:15:23 -0400] \"GET /images/faq.gif HTTP/1.0\" 200 263', '170.142.16.8 - - [12/Jul/1995:13:51:20 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 200 363', 'firewall.dfw.ibm.com - - [12/Jul/1995:15:00:25 -0400] \"GET /history/apollo/images/apollo-logo1.gif HTTP/1.0\" 200 1173', 'pm51.csra.net - - [12/Jul/1995:16:10:54 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', '128.158.56.73 - - [12/Jul/1995:16:31:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'dani.scp.caltech.edu - - [12/Jul/1995:16:42:40 -0400] \"GET /persons/astronauts/a-to-d/CrippenRL.txt HTTP/1.0\" 200 6608', 'jbiagioni.npt.nuwc.navy.mil - - [12/Jul/1995:17:44:07 -0400] \"GET /history/gemini/images/gemini-logo.gif HTTP/1.0\" 200 1284', '198.133.29.18 - - [12/Jul/1995:20:23:19 -0400] \"GET /shuttle/missions/ HTTP/1.0\" 200 12283', 'crc1.cris.com - - [12/Jul/1995:21:15:27 -0400] \"GET /shuttle/missions/sts-70/movies/movies.html HTTP/1.0\" 200 1395', 'slip16.van1.pacifier.com - - [13/Jul/1995:06:44:42 -0400] \"GET /shuttle/countdown/video/livevideo2.gif HTTP/1.0\" 200 72666', '199.77.75.34 - - [13/Jul/1995:09:02:54 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 200 363', 'awright.educ.stratus.com - - [13/Jul/1995:09:10:43 -0400] \"GET /htbin/cdt_clock.pl HTTP/1.0\" 200 751', '130.38.157.237 - - [13/Jul/1995:09:33:50 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0', '128.159.144.97 - - [13/Jul/1995:09:56:25 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 200 669', '163.205.16.35 - - [13/Jul/1995:10:41:34 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 200 363', '150.104.142.39 - - [13/Jul/1995:10:52:10 -0400] \"GET /history/apollo/images/apollo-logo.gif HTTP/1.0\" 200 3047', 'pm-17.qbc.clic.net - - [13/Jul/1995:14:37:55 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0', '128.158.45.8 - - [13/Jul/1995:15:13:13 -0400] \"GET /history/apollo/apollo-13/movies/apo13damage.mpg HTTP/1.0\" 200 297851', 'wpbfl2-53.gate.net - - [13/Jul/1995:15:18:52 -0400] \"GET /shuttle/missions/missions.html HTTP/1.0\" 200 8678', 'www-b2.proxy.aol.com - - [13/Jul/1995:20:34:10 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 200 3564', 'cisasm29.uhc.com - - [13/Jul/1995:23:25:14 -0400] \"GET /shuttle/missions/51-l/ HTTP/1.0\" 200 1712', 'mage.mindspring.com - - [13/Jul/1995:23:32:30 -0400] \"GET /shuttle/missions/sts-71/movies/movies.html HTTP/1.0\" 200 3381', 'piweba1y.prodigy.com - - [14/Jul/1995:01:52:09 -0400] \"GET /shuttle/countdown/video/livevideo2.gif HTTP/1.0\" 200 65576', 'port17.wavenet.com - - [14/Jul/1995:05:31:34 -0400] \"GET /shuttle/missions/missions.html HTTP/1.0\" 200 8678', '163.205.12.162 - - [14/Jul/1995:08:24:40 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 200 234', 'n1132650.ksc.nasa.gov - - [14/Jul/1995:09:57:22 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', 'vcarot.agr.upv.es - - [14/Jul/1995:12:07:54 -0400] \"GET /shuttle/resources/orbiters/challenger.html HTTP/1.0\" 200 8089', 'ewald.chem.cornell.edu - - [14/Jul/1995:17:54:56 -0400] \"GET /icons/menu.xbm HTTP/1.0\" 200 527', 'e659229.boeing.com - - [14/Jul/1995:19:01:50 -0400] \"GET /history/gemini/gemini-3/gemini-3.html HTTP/1.0\" 200 3520', 'siltb10.orl.mmc.com - - [15/Jul/1995:05:15:52 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713', 'dal05-20.ppp.iadfw.net - - [15/Jul/1995:10:44:40 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 4247', 'magmaa.vpro.nl - - [15/Jul/1995:13:04:03 -0400] \"GET /shuttle/countdown/count70.gif HTTP/1.0\" 200 46573', 'felix.filenet.com - - [15/Jul/1995:15:34:32 -0400] \"GET /images/ksclogosmall.gif HTTP/1.0\" 200 3635', 'dynamic-36.premier1.net - - [15/Jul/1995:22:26:07 -0400] \"GET /facilities/mlp.html HTTP/1.0\" 200 2653', 'piweba3y.prodigy.com - - [15/Jul/1995:23:49:26 -0400] \"GET /ksc.html HTTP/1.0\" 200 7071', 'kuts7p03.cc.ukans.edu - - [16/Jul/1995:00:35:23 -0400] \"GET /history/gemini/gemini-1/gemini-1-patch-small.gif HTTP/1.0\" 200 6987', 'goy.dial.eunet.ch - - [16/Jul/1995:09:47:30 -0400] \"GET /images/launchpalms-small.gif HTTP/1.0\" 200 11473', 'f181-123.net.wisc.edu - - [16/Jul/1995:11:35:17 -0400] \"GET /history/apollo/apollo-13/apollo-13-patch-small.gif HTTP/1.0\" 200 12859', 'csee-ppp1.csee.usf.edu - - [16/Jul/1995:20:58:46 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713', 'pipe3.nyc.pipeline.com - - [16/Jul/1995:22:26:14 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 200 669', 'hangout.rutgers.edu - - [17/Jul/1995:00:56:54 -0400] \"GET /history/apollo/apollo-13/apollo-13-patch.jpg HTTP/1.0\" 200 40960', '133.55.0.176 - - [17/Jul/1995:03:05:42 -0400] \"GET /shuttle/missions/sts-63/sts-63-patch-small.gif HTTP/1.0\" 200 16102', 'gw4.att.com - - [17/Jul/1995:09:25:16 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4081', 'cocoa08.ksc.nasa.gov - - [17/Jul/1995:10:10:25 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 200 234', 'sirius.astro.uva.nl - - [17/Jul/1995:10:12:58 -0400] \"GET /shuttle/countdown/video/livevideo.jpeg HTTP/1.0\" 304 0', 'ix-clv1-13.ix.netcom.com - - [17/Jul/1995:10:53:04 -0400] \"GET /history/apollo/images/apollo-logo1.gif HTTP/1.0\" 304 0', '163.205.16.105 - - [17/Jul/1995:15:35:54 -0400] \"GET /ksc.html HTTP/1.0\" 200 7071', '140.229.116.37 - - [17/Jul/1995:16:00:26 -0400] \"GET /shuttle/missions/sts-70/ HTTP/1.0\" 200 3513', 'research.ophth.uci.edu - - [17/Jul/1995:20:36:20 -0400] \"GET /shuttle/technology/sts-newsref/sts-lc39.html HTTP/1.0\" 200 72580', 'siltb10.orl.mmc.com - - [18/Jul/1995:00:45:09 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713', '199.234.151.65.du.nauticom.net - - [18/Jul/1995:03:14:09 -0400] \"GET /history/apollo/images/apollo-logo1.gif HTTP/1.0\" 200 1173', 'www-gds.ksc.nasa.gov - - [18/Jul/1995:07:54:32 -0400] \"GET /images/ksclogosmall.gif HTTP/1.0\" 304 0', '143.91.102.3 - - [18/Jul/1995:12:19:03 -0400] \"GET /shuttle/missions/sts-71/images/KSC-95EC-0544.gif HTTP/1.0\" 200 36712', '139.169.136.146 - - [18/Jul/1995:12:48:54 -0400] \"GET /shuttle/missions/sts-69/mission-sts-69.html HTTP/1.0\" 200 4821', 'basfegw.basf-corp.com - - [18/Jul/1995:16:59:50 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 304 0', 'wdinaso.dialup.cloud9.net - - [18/Jul/1995:18:28:40 -0400] \"GET /persons/astronauts/i-to-l/JemisonMC.txt HTTP/1.0\" 200 4233', 'pandora.lpl.arizona.edu - - [18/Jul/1995:19:00:02 -0400] \"GET /shuttle/missions/sts-26/mission-sts-26.html HTTP/1.0\" 200 7175', 'd42-1.cpe.melbourne.aone.net.au - - [19/Jul/1995:00:31:38 -0400] \"GET /history/apollo/images/footprint-small.gif HTTP/1.0\" 304 0', 'design2.dsar.doc.ca - - [19/Jul/1995:08:58:09 -0400] \"GET /shuttle/missions/sts-70/images/DSC-95EC-0006.jpg HTTP/1.0\" 200 488494', 'engelhard-slip-5343.rutgers.edu - - [19/Jul/1995:11:02:05 -0400] \"GET /shuttle/missions/sts-70/sts-70-patch-small.gif HTTP/1.0\" 200 5026', 'cft6.ppp253.cftnet.com - - [19/Jul/1995:11:28:46 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 200 5866', '192.42.240.14 - - [19/Jul/1995:11:29:02 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'igate.nrc.gov - - [19/Jul/1995:11:37:07 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', '134.131.68.221 - - [19/Jul/1995:14:08:42 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', '163.205.2.179 - - [19/Jul/1995:14:31:06 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'bstfirewall.bst.bls.com - - [19/Jul/1995:14:31:55 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 200 669', 'ix-roc1-07.ix.netcom.com - - [19/Jul/1995:18:42:10 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', '134.120.46.116 - - [19/Jul/1995:19:33:00 -0400] \"GET /history/apollo/images/apollo-small.gif HTTP/1.0\" 200 9630', 'dd08-016.compuserve.com - - [19/Jul/1995:20:33:34 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'ix-tf7-09.ix.netcom.com - - [19/Jul/1995:21:37:04 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 200 234', 'siltb10.orl.mmc.com - - [20/Jul/1995:01:39:23 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204', '194.21.12.53 - - [20/Jul/1995:05:55:02 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 304 0', 'n1127156.ksc.nasa.gov - - [20/Jul/1995:07:19:32 -0400] \"GET / HTTP/1.0\" 200 7071', 'ssrmoef.lsis.loral.com - - [20/Jul/1995:13:16:10 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 200 669', 'pinta.csee.usf.edu - - [20/Jul/1995:13:27:57 -0400] \"GET /shuttle/resources/orbiters/atlantis.html HTTP/1.0\" 200 7025', '129.49.70.129 - - [20/Jul/1995:14:03:03 -0400] \"GET /history/apollo/images/footprint-small.gif HTTP/1.0\" 304 0', 'apollo.gsfc.nasa.gov - - [20/Jul/1995:16:58:26 -0400] \"GET /icons/sound.xbm HTTP/1.0\" 200 530', 'unifex.ksc.nasa.gov - - [20/Jul/1995:19:06:34 -0400] \"GET / HTTP/1.0\" 200 7071', 'piweba4y.prodigy.com - - [20/Jul/1995:23:27:54 -0400] \"GET /shuttle/missions/sts-70/sts-70-patch-small.gif HTTP/1.0\" 200 5978', 'bldg200.100-13.hsis.mc.uci.edu - - [21/Jul/1995:02:43:40 -0400] \"GET /shuttle/missions/missions.html HTTP/1.0\" 200 8678', '198.133.29.18 - - [21/Jul/1995:07:19:41 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 200 363', '192.246.43.103 - - [21/Jul/1995:14:46:54 -0400] \"GET /shuttle/missions/sts-70/images/DSC-95EC-0001.gif HTTP/1.0\" 200 107133', '194.77.139.1 - - [21/Jul/1995:21:49:06 -0400] \"GET /ksc.html HTTP/1.0\" 200 7071', '205.139.170.201 - - [22/Jul/1995:00:13:22 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786', 'philb.tiac.net - - [22/Jul/1995:02:36:59 -0400] \"GET /shuttle/missions/sts-1/mission-sts-1.html HTTP/1.0\" 200 8393', 'www-d3.proxy.aol.com - - [22/Jul/1995:04:24:18 -0400] \"GET /history/apollo/images/apollo-logo1.gif HTTP/1.0\" 200 1173', 'www-c1.proxy.aol.com - - [23/Jul/1995:20:18:28 -0400] \"GET /images/ HTTP/1.0\" 200 17688', 'smf-b12.facsmf.utexas.edu - - [23/Jul/1995:21:34:05 -0400] \"GET /history/apollo/images/apollo-logo1.gif HTTP/1.0\" 200 1173', '193.77.12.89 - - [24/Jul/1995:06:30:36 -0400] \"GET /shuttle/countdown/count70.gif HTTP/1.0\" 200 46573', 'ppp27.cuug.ab.ca - - [24/Jul/1995:09:14:30 -0400] \"GET /images/landing.jpg HTTP/1.0\" 200 439760', 'main3.main.com - - [24/Jul/1995:13:03:49 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 304 0', 'atluw02.dbsoftware.com - - [24/Jul/1995:13:08:27 -0400] \"GET /shuttle/technology/images/srb_mod_compare_3-small.gif HTTP/1.0\" 200 55666', '140.215.77.21 - - [24/Jul/1995:13:53:45 -0400] \"GET /history/mercury/mr-3/mr-3.html HTTP/1.0\" 200 1124', '139.169.5.44 - - [24/Jul/1995:15:50:05 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 200 363', '205.221.75.72 - - [24/Jul/1995:16:25:34 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 200 234', 'mach.physics.ubc.ca - - [24/Jul/1995:17:23:55 -0400] \"GET /images/slf-logo.gif HTTP/1.0\" 200 10966', 'ppp2.cs.rit.edu - - [25/Jul/1995:00:30:19 -0400] \"GET /icons/menu.xbm HTTP/1.0\" 200 527', 'dd11-030.compuserve.com - - [25/Jul/1995:01:44:56 -0400] \"GET /images/ksclogo-medium.gif HTTP/1.0\" 200 5866', '204.214.38.50 - - [25/Jul/1995:16:38:23 -0400] \"GET /history/apollo/images/footprint-small.gif HTTP/1.0\" 200 18149', 'slip05.unf.edu - - [25/Jul/1995:17:43:47 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 304 0', 'mark.pa.tetherless.com - - [25/Jul/1995:23:13:04 -0400] \"GET /elv/elvpage.htm HTTP/1.0\" 200 8583', 'austin-1-9.i-link.net - - [26/Jul/1995:03:22:02 -0400] \"GET /ksc.html HTTP/1.0\" 200 7096', 'pc121102.shef.ac.uk - - [26/Jul/1995:08:25:57 -0400] \"GET /shuttle/missions/sts-7/news/ HTTP/1.0\" 200 371', '157.89.22.16 - - [27/Jul/1995:10:33:14 -0400] \"GET /shuttle/missions/51-a/51-a-patch-small.gif HTTP/1.0\" 200 13282', '128.180.36.2 - - [27/Jul/1995:15:00:46 -0400] \"GET /shuttle/missions/51-l/ HTTP/1.0\" 200 1712', '163.205.11.216 - - [27/Jul/1995:16:23:50 -0400] \"GET /facilities/tour.html HTTP/1.0\" 200 3723', '155.31.23.82 - - [27/Jul/1995:16:53:57 -0400] \"GET /shuttle/missions/sts-70/sts-70-patch-small.gif HTTP/1.0\" 200 5978', 'nntp1.reach.com - - [28/Jul/1995:08:33:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 4324', '137.227.80.241 - - [28/Jul/1995:12:25:25 -0400] \"GET /software/winvn/wvsmall.gif HTTP/1.0\" 200 13372']\n"
     ]
    }
   ],
   "source": [
    "# Make sure you know how much data 0.01% of your dataset is! \n",
    "#It might look like a small fraction, but in the Big Data world \n",
    "#even that might be too much for your local computer!\n",
    "\n",
    "local_sample = \\\n",
    "nasa_logs.sample(withReplacement=False,fraction=0.0001).\\\n",
    "collect()\n",
    "\n",
    "print(local_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb60fd0-d533-42b2-baba-de95fdca16f6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Web server logs like this are called 'semi-structured' for a reason: we can be pretty sure that every line will be formatted the same way. This means every element in each of our Partitions looks pretty much the same after our first step. We can be confident that the same unwanted characters ended up inside the elements of all partitions of our RDD. So our next step takes care of removing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de336a1-8093-42f2-b43b-8088ee66d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning: remove the unwanted characters\n",
    "# The dictionary maps three unwanted characters ([, ], and \") to empty strings ('')\n",
    "\n",
    "replacement_dict = {\"[\":'',\"]\":'',\"\\\"\":''}\n",
    "\n",
    "nasa_logs_structured = nasa_logs.map(lambda line : line.split(\" \")).\\\n",
    "filter(lambda line : len(line)==10).\\\n",
    "map(lambda line : [element.translate(str.maketrans(replacement_dict)) \\\n",
    "               \tfor element in line])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dbc0e5-9a29-40d1-9312-09c2fac51c0a",
   "metadata": {},
   "source": [
    "In summary, this code cleaned the data by removing square brackets and double quotes from each element in lines that have exactly 10 elements.\n",
    "\n",
    "Ok, so now our RDD has the following elements: \n",
    "\n",
    "IP/NAME_OF_ORIGIN \n",
    "DATE/TIME, TIMEZONE\n",
    " REQUEST_METHOD\n",
    " RESOURCE_REQUESTED\n",
    " PROTOCOL\n",
    " STATUS_CODE, SIZE_OF_RESOURCE\n",
    "\n",
    "That looks pretty much like a CSV (or a Dataframe) a Data Scientist could work with! We aim to take advantage of our now-structured dataset and see if we can do a bit of Data Science using the RDD API directly. Let's find out where most requests to the NASA web server came from on our dataset. To do this, let's do a little bit of Map-Reduce.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09c2e1e7-ed5f-4cd4-809d-4f906202bc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('199.72.81.55', 1),\n",
       " ('unicomp6.unicomp.net', 1),\n",
       " ('199.120.110.21', 1),\n",
       " ('burger.letters.com', 1),\n",
       " ('199.120.110.21', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take each line of our structured log and return a Key-Value Pair\n",
    "\n",
    "nasa_logs_structured.map(lambda line : (line[0],1) ).take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982a2fd3-2c32-467a-82e7-77a2d24e7806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17572, 'piweba3y.prodigy.com'),\n",
       " (11591, 'piweba4y.prodigy.com'),\n",
       " (9868, 'piweba1y.prodigy.com'),\n",
       " (7852, 'alyssa.prodigy.com'),\n",
       " (7573, 'siltb10.orl.mmc.com')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify and return the five most frequent encounters \n",
    "# like the count program, we create a tuple containing the encounters and a count of 1 \n",
    "# representing its initial occurrence, then compute the total count.\n",
    "\n",
    "nasa_logs_structured.map(lambda line : (line[0],1) ).\\\n",
    "reduceByKey(lambda a,b : a+b).\\\n",
    "map(lambda kv_pair : (kv_pair[1],kv_pair[0])).\\\n",
    "sortByKey(ascending=False).take(5)\n",
    "\n",
    "# The second map() transforms the DataFrame to have the count as the first element \n",
    "# for sorting purposes and the word as the second element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6e5544-d166-4b46-abe3-7d88d1d80243",
   "metadata": {},
   "source": [
    "\n",
    "Exercise 3.1 - Word count in NASA log\n",
    "\n",
    "If we take the element containing NASA's website resource names and we replace the \"/\"s and \".\"s by \" \"s, we sort of get words. Write a word count program to find the top 5 most frequent words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df50e6dd-2aee-4ed5-8915-db3d195f329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step essentially should splits the resource name based on\n",
    "# / and . characters and treats them as word separators.\n",
    "# The result should be a new DataFrame containing these \"cleaned-up\" website resource names.\n",
    "\n",
    "words = nasa_logs_structured.\\\n",
    "map(lambda line : line[6].\\\n",
    "    replace('/',' ').\\\n",
    "    replace('.',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2279c35-f5db-4c0b-bb3f-b30a9ff40d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 2024051),\n",
       " ('history', 296076),\n",
       " ('apollo', 250775),\n",
       " ('shuttle', 655862),\n",
       " ('countdown', 184637)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This step effectively should create a new DataFrame\n",
    "# where each row is a single word extracted from the website resource names.\n",
    "# Use flatMap() method to flattening the list of words into a single level.\n",
    "# Then use a map() transformation to create your count tuple\n",
    "# Finally use a reduceByKey action to calculate the total count for each word\n",
    "\n",
    "words.\\\n",
    "flatMap(lambda line: line.split(\" \")).\\\n",
    "map(lambda word : (word, 1)).\\\n",
    "reduceByKey(lambda a,b : a+b).\\\n",
    "take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a63e098-3ac9-428c-a15f-be208820325a",
   "metadata": {},
   "source": [
    "\n",
    "Reading a CSV file with Core Spark API (RDD API):\n",
    "\n",
    "The RDD API is very powerful, but on its own it has some serious limitations. Ironically, one of its biggest limitations is its usefulness on structured data... like CSV files.\n",
    "\n",
    "We had caught a glimpse of that on the NASA website example, but now let's look at a real-life CSV to illustrate this and introduce the Pandas on Spark API - a powerful API for which the RDD API can work as a beautiful complement.\n",
    "\n",
    "The file below contains data about all pieces owned/maintained by the Metropolitan Museum of Art in New York City. As we've seen before, the RDD API only allows us to load it as a plain text file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57d14c57-da57-461f-ad1b-07be147fbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sc.textFile('data/surveys.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "113c168f-f3e5-4e28-88ff-fae6f57fac7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35550"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00ea7155-cb76-44ff-a449-82145081a653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['record_id,month,day,year,plot_id,species_id,sex,hindfoot_length,weight']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9cdd59a-ec24-4099-a37d-2be7c5e478ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_split = sample_data.map(lambda line : line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16e058dc-d4ba-4c7f-9b60-bcd13ada33f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['record_id',\n",
       "  'month',\n",
       "  'day',\n",
       "  'year',\n",
       "  'plot_id',\n",
       "  'species_id',\n",
       "  'sex',\n",
       "  'hindfoot_length',\n",
       "  'weight'],\n",
       " ['1', '7', '16', '1977', '2', 'NL', 'M', '32', '']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_split.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6760fc08-1bda-48a1-81c5-c93a944bfc0f",
   "metadata": {},
   "source": [
    "Spark Pandas API:\n",
    "\n",
    "The Spark Core RDD API is a powerful tool for operating on very large Data. However, the RDD API and its Functional Programming flavor are not for everyone. Most people dealing with heavy-duty data analytics problems are used to far more structured data types. Whether they're R users or Python users, data people love data that is in a tabular format - a Table in database or a DataFrame in R or Pandas. In most data analysis situations, it is important to be able to mimic some functionality and design choices from the Pandas package as one of the most powerful python packages to analyze data. To cater to this particular user base, Spark maintainers have introduced a new API in Spark v3: Pandas on Spark. As the name suggests, the idea behind this API is to reproduce the user experience from the Pandas package with as many of its methods and operators as possible, but on a very large scale distributed DataFrames. Note that as this API is actively being developed, you might encounter some errors with some functions. Usually, downgrading PySpark or Pandas version can fix those issues.\n",
    "\n",
    "To get started, first let's import the module pyspark.pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7d50dff-80d4-4c17-a33f-33d6cdeda68e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yemon\\anaconda33\\Lib\\site-packages\\pyspark\\pandas\\__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#import PySpark Pandas API\n",
    "#ignore the warning!\n",
    "\n",
    "import pyspark.pandas as ps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff3d838-248f-4082-a741-2fda4054330d",
   "metadata": {},
   "source": [
    "A handy way of using Pandas on Spark is by converting an actual Pandas DataFrame into a Pandas on Spark DataFrame. In this scenario, you would have a regular Pandas DataFrame, created without any calls to Spark that you wish to perform work on in a parallelized or even distributed fashion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5fe4534-5e55-4701-8c71-953fa792b6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's create a Pandas dataframe from a CSV file and then convert it to Pandas on Spark DataFrame\n",
    "import pandas as pd\n",
    "survey_df_local = pd.read_csv(\"data/surveys.csv\")\n",
    "type(survey_df_local)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a588824-0c4d-44e0-9760-92d298566ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>hindfoot_length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>2</td>\n",
       "      <td>NL</td>\n",
       "      <td>M</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>3</td>\n",
       "      <td>NL</td>\n",
       "      <td>M</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>2</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>7</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>3</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id  month  day  year  plot_id species_id sex  hindfoot_length  \\\n",
       "0          1      7   16  1977        2         NL   M             32.0   \n",
       "1          2      7   16  1977        3         NL   M             33.0   \n",
       "2          3      7   16  1977        2         DM   F             37.0   \n",
       "3          4      7   16  1977        7         DM   M             36.0   \n",
       "4          5      7   16  1977        3         DM   M             35.0   \n",
       "\n",
       "   weight  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's look at the data:\n",
    "survey_df_local.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46e249a-a1da-4579-9187-78619eae462d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.pandas.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's create a Spark DataFrame from a Pandas DataFrame!\n",
    "\n",
    "survey_df_distributed = ps.from_pandas(survey_df_local)\n",
    "type(survey_df_distributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a3924-aaab-4c2f-8396-66184c25215c",
   "metadata": {},
   "source": [
    "Now we have a parallelized or distributed DataFrame that looks and behaves just like a regular Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5781840-abb9-4dd7-9ff8-336a7b09a611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>hindfoot_length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>2</td>\n",
       "      <td>NL</td>\n",
       "      <td>M</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>3</td>\n",
       "      <td>NL</td>\n",
       "      <td>M</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>2</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>7</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1977</td>\n",
       "      <td>3</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id  month  day  year  plot_id species_id sex  hindfoot_length  weight\n",
       "0          1      7   16  1977        2         NL   M             32.0     NaN\n",
       "1          2      7   16  1977        3         NL   M             33.0     NaN\n",
       "2          3      7   16  1977        2         DM   F             37.0     NaN\n",
       "3          4      7   16  1977        7         DM   M             36.0     NaN\n",
       "4          5      7   16  1977        3         DM   M             35.0     NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at this DataFrame using some familiar methods: first head()\n",
    "survey_df_distributed.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90dd09e-2429-4206-b93a-58b95907bfc8",
   "metadata": {},
   "source": [
    "Next, we will go through a few examples of how to use Pandas on Spark DataFrame. Accessing columns and rows, as well as slicing a DataFrame works just like in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93dffa16-c4ed-4802-bfc4-2ca02be88a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   NaN\n",
       "1   NaN\n",
       "2   NaN\n",
       "3   NaN\n",
       "4   NaN\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "survey_df_pandas = survey_df_distributed # make a copy of the Spark DataFrame\n",
    "\n",
    "# Access columns by name with two different syntaxes:\n",
    "survey_df_pandas['weight'].head()\n",
    "#survey_df_pandas.weight.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf780b88-ba9f-4c14-a0c7-fa6513af0463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "record_id            11\n",
       "month                 7\n",
       "day                  16\n",
       "year               1977\n",
       "plot_id               5\n",
       "species_id           DS\n",
       "sex                   F\n",
       "hindfoot_length    53.0\n",
       "weight              NaN\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the .iloc() method to access a row by index\n",
    "survey_df_pandas.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d1e8912-e363-4a07-adc8-1ef355d68ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>hindfoot_length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>7</td>\n",
       "      <td>DM</td>\n",
       "      <td>M</td>\n",
       "      <td>37.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>4</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>35.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>8</td>\n",
       "      <td>DO</td>\n",
       "      <td>F</td>\n",
       "      <td>32.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>7</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1977</td>\n",
       "      <td>4</td>\n",
       "      <td>DM</td>\n",
       "      <td>F</td>\n",
       "      <td>35.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    record_id  month  day  year  plot_id species_id sex  hindfoot_length  weight\n",
       "63         64      8   19  1977        7         DM   M             37.0    48.0\n",
       "65         66      8   19  1977        4         DM   F             35.0    46.0\n",
       "67         68      8   19  1977        8         DO   F             32.0    52.0\n",
       "78         79      8   19  1977        7         DM   F             34.0    42.0\n",
       "81         82      8   19  1977        4         DM   F             35.0    41.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use conditionals to find subsets of a DataFrame that match a condition\n",
    "survey_df_pandas[survey_df_pandas.weight > 40].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db3399b1-a88a-4a20-918a-16139bce80c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>hindfoot_length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35549.000000</td>\n",
       "      <td>35549.000000</td>\n",
       "      <td>35549.000000</td>\n",
       "      <td>35549.000000</td>\n",
       "      <td>35549.000000</td>\n",
       "      <td>31438.000000</td>\n",
       "      <td>32283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17775.000000</td>\n",
       "      <td>6.474022</td>\n",
       "      <td>16.105966</td>\n",
       "      <td>1990.475231</td>\n",
       "      <td>11.397001</td>\n",
       "      <td>29.287932</td>\n",
       "      <td>42.672428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10262.256696</td>\n",
       "      <td>3.396583</td>\n",
       "      <td>8.256691</td>\n",
       "      <td>7.493355</td>\n",
       "      <td>6.799406</td>\n",
       "      <td>9.564759</td>\n",
       "      <td>36.631259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1977.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8888.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17772.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26661.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35549.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>280.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          record_id         month           day          year       plot_id  hindfoot_length        weight\n",
       "count  35549.000000  35549.000000  35549.000000  35549.000000  35549.000000     31438.000000  32283.000000\n",
       "mean   17775.000000      6.474022     16.105966   1990.475231     11.397001        29.287932     42.672428\n",
       "std    10262.256696      3.396583      8.256691      7.493355      6.799406         9.564759     36.631259\n",
       "min        1.000000      1.000000      1.000000   1977.000000      1.000000         2.000000      4.000000\n",
       "25%     8888.000000      4.000000      9.000000   1984.000000      5.000000        21.000000     20.000000\n",
       "50%    17772.000000      6.000000     16.000000   1990.000000     11.000000        32.000000     37.000000\n",
       "75%    26661.000000      9.000000     23.000000   1997.000000     17.000000        36.000000     48.000000\n",
       "max    35549.000000     12.000000     31.000000   2002.000000     24.000000        70.000000    280.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics\n",
    "survey_df_pandas.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "081fd0da-5a73-44d9-a283-8d86583ff7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.672428212991356"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# location measures\n",
    "survey_df_pandas.weight.mean()\n",
    "#survey_df_pandas.weight.median()\n",
    "#survey_df_pandas.weight.quantile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0425aa86-e2b3-4a1a-9d9e-989ccad88f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341.8491706942696"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dispersion measures:\n",
    "#survey_df_pandas.weight.std()\n",
    "survey_df_pandas.weight.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec48fd-4037-4e43-964b-9345d4d57fa2",
   "metadata": {},
   "source": [
    "Last, but not least, Pandas on Spark introduces the plot class along with its subclasses that allow you to easily create different types of plots. Before Pandas on Spark, it would have been necessary to bring data over from the cluster to the Driver in order to visualize it. Of course, this would have been impractical with very large datasets that do not fit in the Driver's memory. With this new API, plot objects are generated directly on the cluster and only then returned to the Driver for you to see!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d71f7-8dd4-4ca8-8a67-0c35943b696f",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "* Parallelizing a DataFrame does not necessarily mean any arbitrary operation will run faster. In general, you can expect Pandas on Spark to outperform Pandas as the size of a DataFrame grows, even if you are running PySpark on a single node. That being said, you should always reason about scalability before choosing to parallelize work over multiple cores, or multiple nodes. See this article for more about scalability: https://docs.alliancecan.ca/wiki/Scalability\n",
    "\n",
    "* Pandas on Spark is not a 100% perfect clone of Pandas - some Pandas functionalities have not yet been implemented, some probably never will be, and Pandas on Spark have a few features that do not exist on Pandas. See the complete API reference for more details: https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b2a154-e016-4ec1-83a5-1ab717a4a2d0",
   "metadata": {},
   "source": [
    "Exercise 4.1 \n",
    "\n",
    "Use pandas on Spark API:\n",
    "\n",
    "* Create a parallel query that finds all rows with a weight value greater than 50 and hindfoot_length larger than 52, and then calculate the summary statistics of these rows.\n",
    "\n",
    "* Hint: You can use where() method to introduce two different conditions in your search and dropna() method to remove rows with missing values in weight or hindfoot_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efb0a777-e9ad-4536-a720-b22411307cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>plot_id</th>\n",
       "      <th>hindfoot_length</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8102.560847</td>\n",
       "      <td>6.391534</td>\n",
       "      <td>13.232804</td>\n",
       "      <td>1983.380952</td>\n",
       "      <td>7.328042</td>\n",
       "      <td>53.534392</td>\n",
       "      <td>137.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5436.685915</td>\n",
       "      <td>3.163141</td>\n",
       "      <td>7.784244</td>\n",
       "      <td>3.902108</td>\n",
       "      <td>5.801532</td>\n",
       "      <td>0.866107</td>\n",
       "      <td>17.657543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>392.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1977.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3914.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1981.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6844.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1982.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12973.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28927.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>172.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          record_id       month         day         year     plot_id  hindfoot_length      weight\n",
       "count    189.000000  189.000000  189.000000   189.000000  189.000000       189.000000  189.000000\n",
       "mean    8102.560847    6.391534   13.232804  1983.380952    7.328042        53.534392  137.740741\n",
       "std     5436.685915    3.163141    7.784244     3.902108    5.801532         0.866107   17.657543\n",
       "min      392.000000    1.000000    1.000000  1977.000000    1.000000        53.000000   51.000000\n",
       "25%     3914.000000    4.000000    7.000000  1981.000000    2.000000        53.000000  129.000000\n",
       "50%     6844.000000    6.000000   12.000000  1982.000000    8.000000        53.000000  140.000000\n",
       "75%    12973.000000    9.000000   20.000000  1987.000000    9.000000        54.000000  150.000000\n",
       "max    28927.000000   12.000000   31.000000  1998.000000   22.000000        58.000000  172.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exercise 4.1 Solution\n",
    "\n",
    "filtered_df = (\n",
    "    survey_df_pandas\n",
    "    .where((survey_df_pandas.weight > 50) & (survey_df_pandas.hindfoot_length > 52))\n",
    "    .dropna(subset=[\"weight\", \"hindfoot_length\"])  # Remove rows with missing values in weight or hindfoot_length\n",
    "  \n",
    ")\n",
    "filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f3511-cf14-41e0-99d4-ed21b885d36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
