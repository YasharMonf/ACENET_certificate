{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa24d9a-9f27-4c6e-a2c5-105da7cfe881",
   "metadata": {},
   "source": [
    "Big data analysis with PySpark\n",
    "\n",
    "Make sure you install PySpark library from Anaconda prompt (windows) or terminal (Mac) using the following command:\n",
    "\n",
    "conda install -c conda-forge pyspark\n",
    "\n",
    "and then run the following commands in your terminal (Mac) or Anaconda prompt (windows):\n",
    "\n",
    "set PYSPARK_DRIVER_PYTHON=jupyter\n",
    "set PYSPARK_DRIVER_PYTHON_OPTS='notebook'\n",
    "\n",
    "\n",
    "When you done, run the following test code to make sure PySpark works, if you don't get any errors, you are good to go!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e443a5-aab7-4e2a-b064-9e136023cdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [1], [2], [3], [4], [5], [], [6], [7], [8], [9], [10]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Big Data Analysis with PySpark\n",
    "# test code (only run this code after you install PySpark and Set the parameters in Anaconda Prompt or Terminal\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "some_numbers = [1,2,3,4,5,6,7,8,9,10]\n",
    "my_first_rdd = sc.parallelize(some_numbers)\n",
    "my_first_rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecaa91a-1852-4f5e-97cb-1edd0d803cfe",
   "metadata": {},
   "source": [
    "In this section you will dive deeper into the Spark Core API or Spark RDD API. You will not only learn by example how to write code using this API, but you will also learn about important properties of RDDs and Spark itself. Let's start by importing PySpark - a package that enables you to use Spark APIs in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56383f54-41be-436a-9777-dcaec852cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to import PySpark\n",
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c546e656-d49c-476a-9399-8320bf710c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a Spark cluster's connection\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c411d6fa-bc63-4321-9e9e-4f74049f4dc7",
   "metadata": {},
   "source": [
    "SparkContext is the primary point of entry for Spark capabilities. A SparkContext represents a Spark cluster’s connection that is useful in building RDDs and broadcast variables on the cluster. It enables your Spark application to connect to the Spark Cluster using Resource Manager. After creating the SparkContext, you can use it to create RDDs, broadcast variables, and accumulators, as well as access Spark services and perform jobs. All of this can be done until SparkContext is terminated. \n",
    "\n",
    "Now that we have our Spark session initialized on the sc object, we are ready to create RDDs. There are two ways to create an RDD and have a Spark partition and distribute data across the cluster. Let's look at the first one - the parallelize method (usually used for small to medium size datasets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e86e45-8749-46c7-aeed-03d5f7d290df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:287\n"
     ]
    }
   ],
   "source": [
    "# Let's create an RDD containing a small list with integers for elements:\n",
    "\n",
    "some_numbers = [1,2,3,4,5,6,7,8,9,10]\n",
    "my_first_rdd = sc.parallelize(some_numbers)\n",
    "print(my_first_rdd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b8eea-84df-4414-aae0-4d32df04de98",
   "metadata": {},
   "source": [
    "The parallelize() method in PySpark is used to create an RDD (Resilient Distributed Dataset) from a list or any other iterable collection in Python. This method is particularly useful for testing and small datasets as it allows you to quickly create an RDD without reading data from external storage. The second method to create an RDD and have a Spark partition is read from external storage. This method involves creating an RDD by reading data from external storage systems. This is the common method used for handling large datasets.\n",
    "\n",
    "So what happened here? Spark took our list of integers and broke it down into several chunks, called Partitions. Each of these partitions can be operated on independently from each other by Executors, enabling Spark to \"divide and conquer\" and perform computations on your data in parallel.\n",
    "\n",
    "The output message gives us valuable information about RDD. \n",
    "\n",
    "ParallelCollectionRDD: This indicates the type of RDD. In PySpark, ParallelCollectionRDD is an RDD that is created by parallelizing a local collection (like a list or an array) into an RDD.\n",
    "\n",
    "32: This number typically represents a unique identifier for the RDD within the context of the Spark application. It's an internal ID used by Spark to track the RDD.\n",
    "\n",
    "ReadRDDFromFile: refers to an internal method used by Spark when handling data read from local collections or files.\n",
    "\n",
    "PythonRDD.scala: This specifies the source file in the Spark codebase where the relevant class or method is defined. PythonRDD is a class that handles RDD operations in the context of Python, part of PySpark's internals.\n",
    "\n",
    "287: This indicates the line number in the PythonRDD.scala file where the operation to create this RDD was invoked or defined. This is useful for debugging purposes and understanding the internals of Spark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b7fba29-0048-43ee-8fd2-905915395f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how many partitions Spark broke our list of numbers into\n",
    "my_first_rdd.getNumPartitions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5f009-a5a5-4b5d-8486-b24ed0a54706",
   "metadata": {},
   "source": [
    "getNumPartitions() method returns the number of partitions created by Spark to parallelize your program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec5a4e0-9417-49fc-ab2a-9b56fcf7b875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [1], [2], [3], [4], [5], [], [6], [7], [8], [9], [10]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's try to collect the actual data from cluster!\n",
    "\n",
    "my_first_rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31db878a-5aa8-4574-bc82-21b9ab3998d4",
   "metadata": {},
   "source": [
    "Let's analyze the code components:\n",
    "\n",
    "Here, glom() method can be used to gather each partition's data into a list, and collect() method can be used to preview the partitions. Together, they will allow you to see the contents of partitions as a list.\n",
    "\n",
    "The number of Partitions is one of the important parameters of a Spark program that you need to be aware of. Split your data into too few partitions and Spark will not be able to do as much work in parallel as your Cluster hardware enables it to do; split it into too many and you may end up with empty partitions or not fully taking advantage of parallelism again, by forcing Executors to perform lots of very small tasks sequentially.\n",
    "\n",
    "When you create an RDD using parallelize(), you can specify the number of partitions as a second argument. If you don't specify it, Spark will use a default value, which is typically the total number of cores on your local machine when running in local mode.\n",
    "\n",
    "The number of partitions is not directly equal to the number of CPUs, but there is a relationship between them. In general, you want to have enough partitions to keep all your CPUs busy. However, the optimal number of partitions depends on various factors including the nature of the data, the complexity of the transformations, and the underlying infrastructure.\n",
    "\n",
    "A common rule of thumb is to have at least as many partitions as the number of cores available in your cluster. In many cases, having 2-3 times the number of partitions as the total number of cores can provide better parallelism and load balancing. For example, if you have a cluster with 16 cores, you might start with 32-48 partitions.\n",
    "\n",
    "Having more partitions than cores ensures that there are enough tasks to keep all the cores busy. If you have exactly the same number of partitions as cores, once a task finishes, that core might be idle if there are no more tasks left to process. By having more partitions, you ensure that new tasks are always ready to be picked up by cores as soon as they become free.\n",
    "\n",
    "Example: Suppose you have 16 cores and exactly 16 partitions. If one task finishes early, that core will sit idle until all other tasks finish. With 32 partitions, as soon as a core finishes a task, it can immediately pick up another one, improving overall resource utilization.\n",
    "\n",
    "In windows, to figure out how many cores your PC has, Press Ctrl + Shift + Esc to open Task Manager. Select the Performance tab and select CPU to see how many cores and logical processors your PC has. Here the physical cores are number of physical cores, actual hardware components. Logical cores are the number of physical cores times the number of threads that can run on each core through the use of hyperthreading. For example, my 6-core processor runs two threads per core, so I have 12 logical processors, and therefore, Spark usually use 12 partitions as a default value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20bf95be-c7f5-428f-8654-c2b13d58269e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's set the number of partions to 10\n",
    "my_first_rdd_repartitioned = my_first_rdd.repartition(10)\n",
    "my_first_rdd_repartitioned.getNumPartitions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d3498-2f29-4742-a6aa-93e3b5627a67",
   "metadata": {},
   "source": [
    "Using the time library, we can measure the time required to complete the tasks and optimize the number of partitions when using PySpark. For collecting the above data from Spark cluster, let’s measure the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48f8c052-afd9-4b8b-a582-9ac91b9ff802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel Runtime: 9.390958547592163 seconds\n"
     ]
    }
   ],
   "source": [
    "# Measure the time of collecting data using time library\n",
    "\n",
    "import time\n",
    "start_time = time.time()  # Record start time\n",
    "\n",
    "my_first_rdd.glom().collect()\n",
    "\n",
    "end_time = time.time()  # Record end time\n",
    "\n",
    "parallel_time = end_time - start_time\n",
    "print(\"Parallel Runtime:\", parallel_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db500ef1-a0ba-48e9-bd50-b21ff3f8b362",
   "metadata": {},
   "source": [
    "Exercise #1:\n",
    "\n",
    "Change the number of partitions and see how the time required for completing this parallel task will vary with the number of partitions. Think about the trend you observe and try to explain the trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f7a4a0e-ac30-4a06-824b-585bde6cb636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel Runtime: 9.738492727279663 seconds\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1 solution:\n",
    "\n",
    "\n",
    "start_time = time.time()  # Record start time\n",
    "\n",
    "my_first_rdd_repartitioned = my_first_rdd.repartition(5)\n",
    "my_first_rdd.glom().collect()\n",
    "\n",
    "end_time = time.time()  # Record end time\n",
    "\n",
    "parallel_time = end_time - start_time\n",
    "print(\"Parallel Runtime:\", parallel_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa718275-babf-4667-9be3-67f6bb13b3ff",
   "metadata": {},
   "source": [
    "The RDD API has two main types of methods: Transformations and Actions. In a nutshell, Transformations are operations carried out on RDDs that return other RDDs. Actions are operations carried out on RDDs that do not return other RDDs. On the line above, repartition is a Transformation and getNumPartitions is an Action. Let's look at a few more examples to see what that means in practice:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db17f6a4-420b-4594-9165-527170f65e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[20] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our first meaningful transformation to our RDD: add 1 to each element\n",
    "\n",
    "my_first_rdd_repartitioned.map(lambda element : element+1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1703d36-6556-46d1-926d-37cb9e148e1d",
   "metadata": {},
   "source": [
    "In this example, we used map() method with lambda expression. The map method applies a function to each element of each partition of an RDD. Python Lambda Functions are anonymous functions meaning that the function is without a name. As we already know the def keyword is used to define a normal function in Python. Similarly, the lambda keyword is used to define an anonymous function in Python. This line of code is performing a transformation on an existing RDD (my_first_rdd_repartitioned). Specifically, it uses the map function to apply a lambda function to each element of the RDD. The lambda function takes each element and adds 1 to it. In this context, the lambda function is applied to each element of the RDD.\n",
    "\n",
    "\n",
    "The output above tells us that this returned another RDD. Can we get its contents back from the cluster?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9688e3c-d192-4b83-aaea-0979613b8313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 5, 6, 7, 3, 10, 1, 2, 4, 8]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The collect() method brings the contents of an RDD from the cluster back to the driver\n",
    "\n",
    "my_first_rdd_repartitioned.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e3d201-959d-4add-ae1b-c249f138777d",
   "metadata": {},
   "source": [
    "The numbers may be shuffled, but this is still our list of integers from 1 to 10... we had applied a transformation to our RDD, which created another RDD, but we had no way to refer to this new RDD!\n",
    "\n",
    "To summarize: there are two types of RDD operations: transformations, which yield a new RDD, and actions, which return a value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "059c824b-0c5a-48a5-97dd-a7b3193917ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RDDs are immutable! Our transformation actually created another RDD we had no way to refer to on the Driver!\n",
    "\n",
    "my_second_rdd = my_first_rdd.map(lambda element : element+1)\n",
    "\n",
    "my_second_rdd.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb746387-23da-4e66-b605-b2d6cdabbd5d",
   "metadata": {},
   "source": [
    "By creating new RDDs with each Transformation, Spark actually provides a type of fault-tolerance! It records these transformations, so if ever an entire node or an Executor inside a node fails, Spark can immediately recompute your RDDs and your work isn't lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42e2717e-2f0f-48b9-b60b-d7bf21452168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'(12) PythonRDD[21] at collect at C:\\\\Users\\\\yemon\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_31516\\\\3473384859.py:5 []\\n |   ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:287 []'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark preserves RDD lineage to automatically recompute them if they are lost!\n",
    "\n",
    "my_second_rdd.toDebugString()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c57f9-b3d0-4398-bbf4-57e9734c3ea2",
   "metadata": {},
   "source": [
    "Breakdown of the Output\n",
    "b': The b prefix indicates that the string is a byte string. This can happen if the output was encoded in bytes. It's typically seen in Python 3 when dealing with binary data.\n",
    "\n",
    "(12): This number represents the number of partitions in the RDD. Partitions are subsets of the data that Spark processes in parallel. Here, the RDD has 12 partitions.\n",
    "\n",
    "PythonRDD[33]: This indicates the type and unique ID of the RDD. PythonRDD suggests this RDD was created or transformed using a Python function. The ID [33] is a unique identifier for this RDD.\n",
    "\n",
    "at collect at C:\\\\Users\\\\yemon\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_34836\\\\3473384859.py This shows where the collect action was called on the RDD. The path points to the file and line number in your local environment where this action was invoked.\n",
    "\n",
    "The output indicates the following sequence of events for the RDD:\n",
    "\n",
    "ParallelCollectionRDD[32]: An RDD was created by parallelizing a local collection. This is typically done using sc.parallelize().\n",
    "\n",
    "PythonRDD[33]: This RDD is derived from ParallelCollectionRDD[32] and is transformed using a Python function.\n",
    "\n",
    "collect action: The collect action was called on PythonRDD[33], triggering the computation to return the RDD's elements to the driver.\n",
    "\n",
    "\n",
    "In spark, dependencies in the RDDs are logged in as a graph. In simpler words , every step is part of lineage. By calling the toDebugString method you are essentially asking to get this lineage graph(aka chain of every individual step that happened i.e type of RDD created and method used to create it) to be displayed. The code my_second_rdd.toDebugString() is used in PySpark to get a detailed, human-readable description of an RDD's lineage. This method is particularly useful for understanding how an RDD was constructed, what transformations were applied, and where it sits in the overall computation graph.\n",
    "\n",
    "\n",
    "\n",
    "Now wait a minute... if Spark creates RDDs at every Transformation and Spark keeps things in memory... won't you quickly run out of memory by applying Transformations to RDDs?\n",
    "\n",
    "The answer is: no! Spark performs \"Lazy-Evaluation\". This means all Spark does is record your transformations in a directed acrlyc graph (DAG) without actually computing anything or using up any extra memory until an Action is called on an RDD!\n",
    "\n",
    "Let's get a feeling of this concept by applying a long chain of Transformations to an RDD and timing it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00d19a59-c9e2-4290-8121-d893ad926a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 997 µs\n"
     ]
    }
   ],
   "source": [
    "# Spark performs Lazy-Evaluation: No transformation\n",
    "#actually gets computed until an \"action\" is called on an RDD\n",
    "\n",
    "%time my_third_rdd = my_first_rdd_repartitioned.map(lambda element : element+1).\\\n",
    "filter(lambda element : element % 2 ==0).map(lambda element : element+2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35a612-ae35-4c30-a021-8f9bbd754f23",
   "metadata": {},
   "source": [
    "It ran almost instantly! This code snippet performs a series of transformations on an existing RDD (my_first_rdd_repartitioned) and measures the execution time of these operations using the %time magic command (which is available in Jupyter notebooks and IPython environments). Filter method is a new transformation here. This transformation filters the RDD, keeping only the elements that satisfy the condition element % 2 == 0 (i.e., the element is even). The last map transformation applies another lambda function to each remaining element of the RDD, adding 2 to each even element.\n",
    "\n",
    "Now let's call an Action on this RDD and time it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65732aa0-e894-4708-ab4b-8f7902a40b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 4.03 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The \"reduce\" method is an \"action\". For a complete list of actions,\n",
    "#see: https://spark.apache.org/docs/latest/rdd-programming-guide.html#actions\n",
    "\n",
    "%time my_third_rdd.reduce(lambda a,b : a+b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad57b28-ea5f-412c-8b0f-4f82553d9885",
   "metadata": {},
   "source": [
    "The reduce function is an action in Spark that aggregates the elements of an RDD using a specified binary function. It takes a function that operates on two elements of the RDD at a time and returns a single aggregated result. The function provided here is a lambda function lambda a, b: a + b, which sums two elements. This lambda function takes two arguments a and b and returns their sum a + b. The reduce operation proceeds by combining elements of the RDD pairwise until only a single result remains.\n",
    "\n",
    "And here is some good news for those of you who can't get used to the \"lambda function\" syntax. This also works just fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48abddf9-b7c0-4828-93e5-35bbdc699e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 4.12 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_numbers(a,b):\n",
    "\treturn a+b\n",
    "\n",
    "%time my_third_rdd.reduce(add_numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f9e61-232b-4e7c-9f04-739dddf9f947",
   "metadata": {},
   "source": [
    "RDDs are a pretty powerful concept and if you take anything home from this workshop let it be this: RDDs are a simple way of performing Data Parallelism. In other words, you can write your code almost the exact same way you would in a serial program (i.e., not parallel) and the \"parallel\" part simply means your code will run against different chunks of your data at the same time. All you need to do most of the time is wrap your usual code with one or more RDD API methods and be aware of the nature of the elements in your Partitions, so you pick the right method. Once you've done that, Spark takes care of performing Data Parallelism for you! Here is a slightly more difficult example - let's use Spark to multiply each element of a numpy array by a random number.\n",
    "\n",
    "What makes this more difficult? Now we are doing Data Parallelism not on a native Python object like before (a list), but on an object defined by a non-native library: numpy.\n",
    "\n",
    "We start by creating this object: a 1-d array of 100 elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "288d9c59-d943-4e92-8832-fcbaa478c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "an_object = np.linspace(0,1,100)\n",
    "\n",
    "an_object\n",
    "\n",
    "my_new_rdd = sc.parallelize(an_object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb9c2f-cd66-47ca-b371-f4338df761c3",
   "metadata": {},
   "source": [
    "Now you might be tempted to do like we did before and just do what you would do on your own workstation without Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9b0f2ff-a939-44bb-a2c2-300c9a7a78c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.00826538313486573,\n",
       " 0.00034108213014716,\n",
       " 0.026812767794947498,\n",
       " 0.007235315937175272,\n",
       " 0.029109312117678907,\n",
       " 0.04107054629664143,\n",
       " 0.012208289992239559,\n",
       " 0.057203165983461174,\n",
       " 0.015475122047686862,\n",
       " 0.077854976309951,\n",
       " 0.0823808728287687,\n",
       " 0.04470566094074968,\n",
       " 0.1048481517951939,\n",
       " 0.12861563859490485,\n",
       " 0.060642030363338706,\n",
       " 0.0600329696776155,\n",
       " 0.027772788037093744,\n",
       " 0.12521546532414496,\n",
       " 0.14024540621533166,\n",
       " 0.03968850460762085,\n",
       " 0.0835821717985252,\n",
       " 0.21339468099723988,\n",
       " 0.10119247585378977,\n",
       " 0.1754062285719478,\n",
       " 0.06624657490667155,\n",
       " 0.18516873514657733,\n",
       " 0.24917583306224958,\n",
       " 0.23350067589227638,\n",
       " 0.132689720946891,\n",
       " 0.1495203919866341,\n",
       " 0.18763646831729097,\n",
       " 0.3176066531714394,\n",
       " 0.04519275598044707,\n",
       " 0.16286996963412897,\n",
       " 0.08846320582767389,\n",
       " 0.12999915830152123,\n",
       " 0.22621506508602446,\n",
       " 0.14696706910942336,\n",
       " 0.35885119948622957,\n",
       " 0.05333791691843269,\n",
       " 0.2489544032213848,\n",
       " 0.09133781481247998,\n",
       " 0.15452764564314295,\n",
       " 0.39157564837712616,\n",
       " 0.060955751711326285,\n",
       " 0.4242407752005297,\n",
       " 0.11247112999197895,\n",
       " 0.17156168119191198,\n",
       " 0.40914552810012966,\n",
       " 0.2122219068535117,\n",
       " 0.31228028457989493,\n",
       " 0.44183804951331845,\n",
       " 0.2557264239067495,\n",
       " 0.5256715692822114,\n",
       " 0.33253827661614954,\n",
       " 0.35318597414890807,\n",
       " 0.3792158406738135,\n",
       " 0.2220608148528443,\n",
       " 0.2573834607504428,\n",
       " 0.17107423545554465,\n",
       " 0.558911607383538,\n",
       " 0.17509291670053717,\n",
       " 0.11839746455568978,\n",
       " 0.5645003194176119,\n",
       " 0.267060382313325,\n",
       " 0.6630292056661803,\n",
       " 0.5333212614464792,\n",
       " 0.45641405390511486,\n",
       " 0.06754729690978144,\n",
       " 0.5406746859831942,\n",
       " 0.42787673499071294,\n",
       " 0.3392991553867365,\n",
       " 0.6912547649335217,\n",
       " 0.5078871731845639,\n",
       " 0.07655644315730843,\n",
       " 0.5462362848676144,\n",
       " 0.16470883963900046,\n",
       " 0.3388444734458352,\n",
       " 0.5265134981842405,\n",
       " 0.3766301361989211,\n",
       " 0.4703758127626047,\n",
       " 0.7954342164304785,\n",
       " 0.13756757809209036,\n",
       " 0.47180597080800035,\n",
       " 0.4046635335519133,\n",
       " 0.06507759070431841,\n",
       " 0.10624901485255803,\n",
       " 0.783720531294102,\n",
       " 0.3264822986933383,\n",
       " 0.10629846933067769,\n",
       " 0.2994495635810948,\n",
       " 0.9042775521381282,\n",
       " 0.13879381526522552,\n",
       " 0.4648710829731566,\n",
       " 0.1294952348632319,\n",
       " 0.06466499518094718,\n",
       " 0.2780879323736293,\n",
       " 0.4003507760792532,\n",
       " 0.40198345102163513]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_new_rdd.map(lambda element : element * np.random.rand()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c2dc21-b4f7-421b-bdb2-1144812d238a",
   "metadata": {},
   "source": [
    "This should have failed if you are running on a Cluster (as opposed to running Spark on a single computer). Why? Well, you imported the numpy library on the Driver, but you are asking the Executors to use it... you need to tell the Executors to import numpy too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8635237f-aaba-4ed5-8c4c-ca7aca913360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.00812202160953058,\n",
       " 0.009888215613162834,\n",
       " 0.022715492630669448,\n",
       " 0.008659391685772757,\n",
       " 0.03448168602599533,\n",
       " 0.027560703653753585,\n",
       " 0.016443101228011472,\n",
       " 0.018815385184661183,\n",
       " 0.0876795285736796,\n",
       " 0.05417207548205051,\n",
       " 0.041080454767260834,\n",
       " 0.11426797302917423,\n",
       " 0.048251363091528394,\n",
       " 0.11467419587443911,\n",
       " 0.04053628403353266,\n",
       " 0.14315245912768274,\n",
       " 0.03198870335061044,\n",
       " 0.09897123735442913,\n",
       " 0.13158943507542234,\n",
       " 0.057051633321580565,\n",
       " 0.07462888455352489,\n",
       " 0.17398915898689493,\n",
       " 0.09718231748087326,\n",
       " 0.035949209765678815,\n",
       " 0.24998969499875554,\n",
       " 0.24283422445191372,\n",
       " 0.2411938810633507,\n",
       " 0.14492573438244377,\n",
       " 0.1372208308889884,\n",
       " 0.14542315429596428,\n",
       " 0.032982778206575324,\n",
       " 0.0009364628095138021,\n",
       " 0.3289465565571908,\n",
       " 0.15724359192730175,\n",
       " 0.08573953761873887,\n",
       " 0.3231652712873657,\n",
       " 0.08366498697149989,\n",
       " 0.0010921911465743566,\n",
       " 0.007830278207876781,\n",
       " 0.2857534928188237,\n",
       " 0.0025939463236285044,\n",
       " 0.35460982735908814,\n",
       " 0.4029073294340829,\n",
       " 0.1592006709400899,\n",
       " 0.061617978619951164,\n",
       " 0.022034671828852676,\n",
       " 0.47221313002036847,\n",
       " 0.19850033511308007,\n",
       " 0.3841264031971524,\n",
       " 0.06164236234763649,\n",
       " 0.12606492199646108,\n",
       " 0.20464861481715962,\n",
       " 0.44772288018840556,\n",
       " 0.3737249404345496,\n",
       " 0.1357595790114423,\n",
       " 0.3068871526997319,\n",
       " 0.24745960650199217,\n",
       " 0.4894175322746808,\n",
       " 0.48998504701673246,\n",
       " 0.2882921067121855,\n",
       " 0.43930888039273763,\n",
       " 0.023769653753490615,\n",
       " 0.48301165510888344,\n",
       " 0.49283022788268444,\n",
       " 0.5636962208843017,\n",
       " 0.37827699793171093,\n",
       " 0.5943556429056148,\n",
       " 0.08347853882921882,\n",
       " 0.478788353194445,\n",
       " 0.2210365631637179,\n",
       " 0.526336836924064,\n",
       " 0.1748594774769513,\n",
       " 0.720042167144451,\n",
       " 0.57372047662787,\n",
       " 0.5194911380794772,\n",
       " 0.0633711030908982,\n",
       " 0.0021973378424855225,\n",
       " 0.2810918182485001,\n",
       " 0.07200696008830526,\n",
       " 0.6880054995294939,\n",
       " 0.12983157623216973,\n",
       " 0.3541145088074981,\n",
       " 0.4552082319333778,\n",
       " 0.7108193889589971,\n",
       " 0.6587078177071731,\n",
       " 0.37940887955315433,\n",
       " 0.13988721475755408,\n",
       " 0.5596347244453019,\n",
       " 0.6581238583612439,\n",
       " 0.3710989752961462,\n",
       " 0.31532070183955146,\n",
       " 0.033371336498854175,\n",
       " 0.6788715704432073,\n",
       " 0.5975972840264809,\n",
       " 0.875140146929553,\n",
       " 0.6922704640849411,\n",
       " 0.26332191700865903,\n",
       " 0.48351360354284123,\n",
       " 0.9839795631415579]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code defines a function that multiplies a single element by a random number\n",
    "#and then applies this function to an RDD using the map transformation.def multiply_by_random(x):\n",
    "\n",
    "def multiply_by_random(x):\n",
    "\timport numpy as np\n",
    "    \n",
    "\treturn x * np.random.rand()\n",
    "    \n",
    "#This last line multiplies the input element x by a random number generated by np.random.rand().\n",
    "# np.random.rand() returns a random float in the range [0.0, 1.0).\n",
    "\n",
    "my_new_rdd.map(lambda element : multiply_by_random(element)).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6748e8-0667-4fe1-932b-41c0db7414a0",
   "metadata": {},
   "source": [
    "map() method is a transformation that applies a function to each element of the RDD.\n",
    "The lambda function lambda element : multiply_by_random(element) takes each element of the RDD and applies the multiply_by_random function to it.\n",
    "\n",
    "Alright! This seems to have worked. but is it the best way to go about doing this? Remember, the map method applies whatever function you pass to it to every single element of each partition!\n",
    "\n",
    "Does that mean we are importing numpy 100 times in this example? Yes, it does.\n",
    "\n",
    "This is a good way to proceed into another very useful Transformation in the RDD API:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ede1eada-da30-48a2-adea-6579ce912248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0006420913277973483,\n",
       " 0.005413505116012295,\n",
       " 0.0036835932297477076,\n",
       " 0.035147944004453,\n",
       " 0.0058057735724303,\n",
       " 0.05877923542836736,\n",
       " 0.03160158096465221,\n",
       " 0.06967279128993041,\n",
       " 0.054005501820067504,\n",
       " 0.017327105353854295,\n",
       " 0.011777305579379135,\n",
       " 0.007499235990222014,\n",
       " 0.11631479878530236,\n",
       " 0.11545088682086957,\n",
       " 0.14982690433642673,\n",
       " 0.12243675426075418,\n",
       " 0.0472953133941451,\n",
       " 0.07113057542906155,\n",
       " 0.04185325846479681,\n",
       " 0.019715014391753015,\n",
       " 0.039586059528881674,\n",
       " 0.0448821952736188,\n",
       " 0.22254719044491159,\n",
       " 0.03550950773879934,\n",
       " 0.00027961650804080127,\n",
       " 0.15531602331420274,\n",
       " 0.1850270874273684,\n",
       " 0.11497642534749183,\n",
       " 0.2865182960559578,\n",
       " 0.2215599719104101,\n",
       " 0.25909242656991643,\n",
       " 0.23859557893595518,\n",
       " 0.1215007225029264,\n",
       " 0.32993533209760273,\n",
       " 0.3277326839953978,\n",
       " 0.03808260073704731,\n",
       " 0.1365252776019683,\n",
       " 0.10146061591735347,\n",
       " 0.2753102081792687,\n",
       " 0.026516793413697056,\n",
       " 0.057696444671271475,\n",
       " 0.2345593688181751,\n",
       " 0.1495624430585001,\n",
       " 0.2519548151138189,\n",
       " 0.4449523276760417,\n",
       " 0.08458615920622982,\n",
       " 0.06473760324679975,\n",
       " 0.11397893110036417,\n",
       " 0.0014082641122318096,\n",
       " 0.42632845743068515,\n",
       " 0.1993872089171935,\n",
       " 0.07220390049073151,\n",
       " 0.0886289826615188,\n",
       " 0.11300902221481657,\n",
       " 0.40762490273055313,\n",
       " 0.559265861614071,\n",
       " 0.4732916092320467,\n",
       " 0.5191757229953203,\n",
       " 0.036312834514926645,\n",
       " 0.07497466190403668,\n",
       " 0.014049675006297705,\n",
       " 0.5972843349157204,\n",
       " 0.20372681834273812,\n",
       " 0.13568004837546327,\n",
       " 0.45486809614996787,\n",
       " 0.23428474088711088,\n",
       " 0.2607101200984073,\n",
       " 0.43419485065781893,\n",
       " 0.4129544801039907,\n",
       " 0.17527554029694953,\n",
       " 0.003843969574093886,\n",
       " 0.34984333416569213,\n",
       " 0.024593832517809958,\n",
       " 0.2554217585489877,\n",
       " 0.34929560981804114,\n",
       " 0.3235884177823879,\n",
       " 0.0038537486923197043,\n",
       " 0.7826100077201983,\n",
       " 0.716884088474103,\n",
       " 0.025028784032176808,\n",
       " 0.4988598692559771,\n",
       " 0.8278259844794977,\n",
       " 0.14162568927772684,\n",
       " 0.20834175415718706,\n",
       " 0.7624011513836655,\n",
       " 0.26797113748015583,\n",
       " 0.25376809035053366,\n",
       " 0.5465901915058068,\n",
       " 0.6009580284041247,\n",
       " 0.6080406400918454,\n",
       " 0.1993348690771117,\n",
       " 0.34944999327990456,\n",
       " 0.8702131538668462,\n",
       " 0.8807463723183621,\n",
       " 0.3395819500135709,\n",
       " 0.6223485652803887,\n",
       " 0.5690045148859574,\n",
       " 0.7674822971283835,\n",
       " 0.9007459640050136]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def partition_multiply_by_random(x):\n",
    "\timport numpy as np\n",
    "\n",
    "    # The next line creates a new list by iterating over each element in the partition x.\n",
    "    #For each element, it multiplies the element by a random number generated by np.random.rand().\n",
    "    # np.random.rand() returns a random float in the range [0.0, 1.0).\n",
    "    \n",
    "\toutput = [element * np.random.rand() for element in x]\n",
    "    \n",
    "\treturn output\n",
    "\n",
    "#The next lambda function lambda partition : partition_multiply_by_random(partition) takes a partition\n",
    "# and then applies the partition_multiply_by_random function to it.\n",
    "\n",
    "my_new_rdd.mapPartitions\\\n",
    "(lambda partition : partition_multiply_by_random(partition)).\\\n",
    "collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8760f9c-9db0-41a8-8173-203599f99124",
   "metadata": {},
   "source": [
    "This code defines a function that multiplies elements in a partition by random numbers and then applies this function to an RDD using the mapPartitions transformation. Instead of applying a function to each element individually (like map), mapPartitions allows you to work with a whole partition at once. This can be more efficient for certain operations. \n",
    "\n",
    "The mapPartition method applies whatever function you pass to it to each Partition, but with one caveat: whatever your function does, it must iterate through the elements of the input Partition. So in practice, this method also applies your function to the elements of a Partition, but it allows you more flexibility to do things like importing libraries only once per partition... or anything else that you don't need done repeatedly for each element of a partition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3251de1b-c334-44ab-91b5-95e40c0bfb62",
   "metadata": {},
   "source": [
    "If your code imports libraries, you need to make sure they are installed on every node of your cluster! Generally, that means asking your system administrator to do it for you. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e7cd0b-2a85-4f76-a137-65176405667d",
   "metadata": {},
   "source": [
    "Exercise 2.2 \n",
    "Create two random numpy arrays each with 1000 elements. Use PySpark, write a parallel code to calculate the summation of each element of these arrays (we need just one single value as the total sum). Compare the computational speed of parallel code with a simple summation code without parallelization. \n",
    "\n",
    "Suggestion: For parallel part, you can use reduce() method action which can aggregates the elements of an RDD, you can combine it with a specific lambda function to perform the summation for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a58d8a58-bdb9-45bd-b2e0-1717fd94ee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum (Non-Parallel): 980.4381053007403\n",
      "Non-Parallel Runtime: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "## Exercise 2.2 Solution (non-parallel code)\n",
    "# Create random NumPy arrays\n",
    "import time \n",
    "import numpy as np\n",
    "start_time_np = time.time()  # Record start time\n",
    "arr1 = np.random.rand(1000)\n",
    "arr2 = np.random.rand(1000)\n",
    "\n",
    "# Non-parallel summation\n",
    "sum_non_parallel = np.sum(arr1) + np.sum(arr2)\n",
    "\n",
    "print(\"Sum (Non-Parallel):\", sum_non_parallel)\n",
    "end_time_np = time.time()  # Record end time\n",
    "\n",
    "non_parallel_time = end_time_np - start_time_np\n",
    "print(\"Non-Parallel Runtime:\", non_parallel_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89f381d2-88aa-460f-8a89-9a95a1dad9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum (Parallel - PySpark): 980.4381053007411\n",
      "Parallel Runtime: 9.7750883102417 seconds\n"
     ]
    }
   ],
   "source": [
    "#Exercise 2.2 solution (parallel code)\n",
    "import time\n",
    "start_time = time.time()  # Record start time\n",
    "\n",
    "# Simulate creating random NumPy arrays on Spark workers\n",
    "data = [arr1, arr2]\n",
    "#print(data)\n",
    "  # Create Spark RDD from data\n",
    "rdd = sc.parallelize(data)\n",
    "\n",
    "#define sum function\n",
    "def p_sum(x):\n",
    "\t\t\n",
    "\treturn sum(x)\n",
    "\n",
    "\n",
    "# This line will perform a parallel sum of elements in an RDD\n",
    "\n",
    "sum_parallel = rdd.map(p_sum).reduce(lambda a, b: a + b)\n",
    "\n",
    "print(\"Sum (Parallel - PySpark):\", sum_parallel)\n",
    "\n",
    "end_time = time.time()  # Record end time\n",
    "\n",
    "parallel_time = end_time - start_time\n",
    "print(\"Parallel Runtime:\", parallel_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de181e-c064-4c42-81e0-33f49ede4b47",
   "metadata": {},
   "source": [
    "Explanation of sum_parallel = rdd.map(p_sum).reduce(lambda a, b: a + b): \n",
    "\n",
    "The reduce action aggregates the elements of the RDD using a specified binary operator, in this case, a lambda function that adds two values. Here, lambda a, b: a + b is a simple function that takes two arguments (a and b) and returns their sum. This function is used by reduce() to combine elements of the RDD.\n",
    "\n",
    "Initial RDD: rdd contains the original data that you want to process and sum.\n",
    "map(p_sum): This applies the p_sum function to each element of rdd. The result is a new RDD where each element has been transformed by the p_sum function.\n",
    "reduce(lambda a, b: a + b): The reduce function takes the transformed RDD and applies the lambda function lambda a, b: a + b to aggregate the elements. The lambda function is repeatedly applied to pairs of elements until a single aggregated value (the sum of all elements) is produced.This reduction operation is performed in parallel across the distributed RDD, taking advantage of Spark's distributed computing capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678dcc65-b7de-4b45-a76b-78398889ab55",
   "metadata": {},
   "source": [
    "Directed Acyclic Graphs\n",
    "\n",
    "Now let's look at what Spark is actually doing when Executors perform work on subsets of your dataset in parallel. In the previous section we discussed how RDDs provide a way for the user to work with data scattered across nodes of a cluster transparently, without caring where data points are physically located. Executors then operate somewhat independently over separate chunks of your overall dataset, called Partitions. We had also previously mentioned that the role of the Driver Process is to translate your code into a representation that allows Spark to divide up tasks among multiple executors. That representation was called a Directed Acyclic Graph (DAG) and we will discuss how that ties together with RDDs to enable Spark to fulfill its promise of providing a user-friendly distributed computing platform.\n",
    "\n",
    "The first API we showed you how to use in this lesson was the Spark Core API. Also known as the RDD API, it is at the base of all other Spark APIs. Spark Core is essentially made up of a set of fundamental operations geared towards parallelizing or vectorizing arbitrary work that you want done over a given dataset. These fundamental operations can be stacked, chained, or otherwise composed into very complex sequences of steps of computations to be done over a dataset. Unlike \"regular programming\" though, all these fundamental operations are functions, which can only take other functions as their arguments. The RDD API is a functional programming framework.\n",
    "\n",
    "To illustrate these ideas, let's have a look at what a \"Word Count\" program looks like in Spark:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f110763-c116-42e6-a43a-75c0f2f1bcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: 1\n",
      "test: 1\n",
      "Spark: 1\n",
      "ADI: 1\n",
      "is: 1\n",
      "document: 1\n",
      "This: 1\n",
      "a: 2\n",
      "therefore: 1\n",
      "an: 1\n",
      "to: 1\n",
      "example: 1\n",
      "Therefore: 2\n",
      "RDD: 1\n",
      "includes: 1\n",
      "few: 2\n"
     ]
    }
   ],
   "source": [
    "#Word count program using PySpark!\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Initialize SparkContext\n",
    "sc = SparkContext(\"local\", \"WordCountApp\")\n",
    "\n",
    "# Read input file\n",
    "input_file = sc.textFile(\"test.txt\", minPartitions=12)\n",
    "\n",
    "\n",
    "# Process data: split lines into words, map each word to a (word, 1) pair, and reduce by key to count occurrences\n",
    "word_counts = input_file.flatMap(lambda line: line.split()) \\\n",
    "                        .map(lambda word: (word, 1)) \\\n",
    "                        .reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Collect the result and print each word with its count\n",
    "for word, count in word_counts.collect():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Stop SparkContext\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d8546-f523-45b9-a309-814da042f11b",
   "metadata": {},
   "source": [
    "Code explanation:\n",
    "\n",
    "sc = SparkContext(\"local\", \"WordCountApp\"): Here, Local is the deployment mode passed to the SparkContext constructor. It specifies that you're running Spark in local mode. Local mode means all the Spark computations will happen on the same machine where your Python script is running, using a single thread. This isn't ideal for large datasets as it doesn't leverage the potential parallelism of multiple cores or a distributed cluster. \"WordCountApp\": This is the application name assigned to your Spark application. It's used for identification and logging purposes. You can choose any descriptive name for your application.\n",
    "\n",
    "input_file = sc.textFile(\"test.txt\"): This reads a text file named test.txt into an RDD (Resilient Distributed Dataset) named input_file. Each line in the text file becomes an element in the RDD.\n",
    "\n",
    "word_counts = input_file.flatMap(lambda line: line.split()).map(lambda word: (word, 1))               .reduceByKey(lambda a, b: a + b)\n",
    "                        \n",
    "This code processes the input data in three main steps:\n",
    "\n",
    "* flatMap(lambda line: line.split()): flatMap Transformation: This splits each line into words. Lambda Function: lambda line: line.split() splits each line into a list of words. Output: The result is a flattened RDD where each word from each line is an individual element.\n",
    "\n",
    "* map(lambda word: (word, 1)): map Transformation: This maps each word to a key-value pair (word, 1). Lambda Function: lambda word: (word, 1) creates a tuple for each word, with the word itself as the key and 1 as the value. Output: The result is an RDD of tuples where each word is paired with the number 1.\n",
    "\n",
    "* reduceByKey(lambda a, b: a + b): reduceByKey Transformation: This reduces the tuples by their key (word) by summing the values. Lambda Function: lambda a, b: a + b adds the values of tuples with the same key. Output: The result is an RDD of tuples where each word is paired with its total count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a67bde1-8527-4822-aed2-38fd36f889d9",
   "metadata": {},
   "source": [
    "You could very naturally describe what the code is doing like this:\n",
    "\n",
    "* Read in the text file\n",
    "* Go through all lines of text and break them down into a list of all words in the file \n",
    "* take each word on the list and put it in a tuple along with the number 1\n",
    "* group together the tuples that contain the same word and sum all the number 1s\n",
    "\n",
    "Here is a cleaner way of writing down the exact same description:\n"
   ]
  },
  {
   "attachments": {
    "1e83d0d5-b3ea-40e5-89dc-9c3e12238839.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "14f7a6e0-1b3b-4f7f-931a-7d2b1cca1b1e",
   "metadata": {},
   "source": [
    "![weww.png](attachment:1e83d0d5-b3ea-40e5-89dc-9c3e12238839.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adab57c3-4269-4ffb-8174-1a00ac6fd145",
   "metadata": {},
   "source": [
    "When we visualize the sequence of steps in this way, a few things that were hidden come to the forefront. Notice how the computation is broken down into two stages. That simply means the operations on the second stage can only start being carried out once the last operation of the first stage is finished being computed. In other words, the second stage depends on the results of the first being completely computed for it to be able to start.\n",
    "\n",
    "But what about the operations inside the first stage? Remember Spark will apply these operations to separate partitions of your dataset in parallel. That means that as soon as one of these operations is done being computed over a partition of the data, the next operation can start on that same partition regardless of what is happening with the other partitions! You don't necessarily need to wait for FlatMap to be applied to the entire dataset before you start computing the map! So even though you see the operations in sequence on that diagram, in practice different partitions, in practice Spark may be assigning different computation tasks over different partitions of a dataset within different Executors!\n",
    "\n",
    "This diagram that allows Spark to \"decide\" which operations can be carried out in parallel and which ones must wait for the results of preceding operations is called a Directed Acyclic Graph, and it is exactly the representation that the Driver Process will create based on your code!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da516c2b-74d6-4a69-9ebd-542f87570a81",
   "metadata": {},
   "source": [
    "Exercise 2.3\n",
    "Download the following text file:\n",
    "\n",
    "GOT.txt\n",
    "\n",
    "Write a parallel program using PySpark to count the number of times word “Westeros” has been used in the text file. Use 6 to 18 partitions to parallel the search and Find out how long it took for the program to run.\n",
    "\n",
    "Suggestion: to use a specific number of partitions, you can specify minPartitions=X as an extra argument when reading the input file. For example for 4 partitions: input_file = sc.textFile(\"GOT.txt\", minPartitions=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af058a1a-99b5-4211-809f-59366f7a87ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of partitions: 4\n",
      "Westeros: 4\n",
      "Parallel Runtime: 8.105057001113892 seconds\n"
     ]
    }
   ],
   "source": [
    "#Word count program using PySpark to count the word \"king\" in the text\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "import time\n",
    "start_time = time.time()  # Record start time\n",
    "   \n",
    "# Initialize SparkContext\n",
    "sc = SparkContext(\"local\", \"WordCountApp\")\n",
    "\n",
    "# Read input file\n",
    "input_file = sc.textFile(\"GOT.txt\", minPartitions=4)\n",
    "\n",
    "\n",
    "# Process data: split lines into words, map each word to a (word, 1) pair, and reduce by key to count occurrences\n",
    "word_counts = input_file.flatMap(lambda line: line.split()) \\\n",
    "                        .map(lambda word: (word, 1)) \\\n",
    "                        .reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "print(\"number of partitions:\", input_file.getNumPartitions())\n",
    "# Collect the result and print each word with its count\n",
    "\n",
    "for word, count in word_counts.collect():\n",
    "    if word == 'Westeros': \n",
    "        print(f\"{word}: {count}\")\n",
    "    \n",
    "# Stop SparkContext\n",
    "sc.stop()\n",
    "end_time = time.time()  # Record end time\n",
    "\n",
    "parallel_time = end_time - start_time\n",
    "print(\"Parallel Runtime:\", parallel_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a148fd5-4799-4b3e-9f77-f317751665fc",
   "metadata": {},
   "source": [
    "In the next session, we will learn how to use Spark Sessions instead of Spark context and also we will start to work with Pandas on Spark API to analyze large dataframes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
